<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>KubernetesKubeadmInstallation HA | William&#39;s Blog</title>
<meta name="keywords" content="kubernetes">
<meta name="description" content="kubeadm方式部署kubernetes高可用集群">
<meta name="author" content="deemoprobe">
<link rel="canonical" href="https://deemoprobe.github.io/posts/tech/kubernetes/kuberneteskubeadminstallation-ha/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.437c6a2af4fc60ed76299fc9cd9077545ae1b4ff1cc6481716ecd767dee77e57.css" integrity="sha256-Q3xqKvT8YO12KZ/JzZB3VFrhtP8cxkgXFuzXZ97nflc=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.89eeec8f36cd08246c59f8970019c7295c6a548ff3bdfb632a7ae687603dd4f5.js" integrity="sha256-ie7sjzbNCCRsWfiXABnHKVxqVI/zvftjKnrmh2A91PU="
        onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://deemoprobe.github.io/img/favicon/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://deemoprobe.github.io/img/favicon/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://deemoprobe.github.io/img/favicon/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://deemoprobe.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://deemoprobe.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js"></script>


<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = ""; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
<meta property="og:title" content="KubernetesKubeadmInstallation HA" />
<meta property="og:description" content="kubeadm方式部署kubernetes高可用集群" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://deemoprobe.github.io/posts/tech/kubernetes/kuberneteskubeadminstallation-ha/" />
<meta property="og:image" content="https://deemoprobe.github.io/img/kubernetes.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-29T14:12:14+08:00" />
<meta property="article:modified_time" content="2023-04-29T14:12:14+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://deemoprobe.github.io/img/kubernetes.png" />
<meta name="twitter:title" content="KubernetesKubeadmInstallation HA"/>
<meta name="twitter:description" content="kubeadm方式部署kubernetes高可用集群"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [

        {
          "@type": "ListItem",
          "position":  1 ,
          "name": "📚文章",
          "item": "https://deemoprobe.github.io/posts/"
        },

        {
          "@type": "ListItem",
          "position":  2 ,
          "name": "👨🏻‍💻 技术",
          "item": "https://deemoprobe.github.io/posts/tech/"
        },

        {
          "@type": "ListItem",
          "position":  3 ,
          "name": "Kubernetes",
          "item": "https://deemoprobe.github.io/posts/tech/kubernetes/"
        }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "KubernetesKubeadmInstallation HA",
      "item": "https://deemoprobe.github.io/posts/tech/kubernetes/kuberneteskubeadminstallation-ha/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "KubernetesKubeadmInstallation HA",
  "name": "KubernetesKubeadmInstallation HA",
  "description": "kubeadm方式部署kubernetes高可用集群",
  "keywords": [
    "kubernetes"
  ],
  "articleBody": "环境说明 宿主机系统：Windows 10 虚拟机版本：VMware® Workstation 16 Pro IOS镜像版本：CentOS Linux release 7.9.2009 集群操作用户：root Kubernetes版本：1.23.0 Etcd版本：3.5.1 Runtime：Docker 20.10 CentOS7安装请参考博客文章：LINUX之VMWARE WORKSTATION安装CENTOS-7\n资源分配 网段划分 Kubernetes集群需要规划三个网段：\n宿主机网段：Kubernetes集群节点的网段 Pod网段：集群内Pod的网段，相当于容器的IP Service网段：集群内服务发现使用的网段，service用于集群容器通信 生产环境根据申请到的IP资源进行分配即可，原则是三个网段不允许有重合IP。IP网段计算可以参考：在线IP地址计算。本文虚拟机练习环境IP地址网段分配如下：\n宿主机网段：192.168.43.1/24 Pod网段：172.16.0.0/12 Service：10.96.0.0/12 节点分配 采用3管理节点2工作节点的高可用Kubernetes集群模式：\nk8s-master01/k8s-master02/k8s-master03 集群的Master节点 三个master节点同时做etcd集群 k8s-node01/k8s-node02 集群的Node节点 k8s-master-vip做高可用k8s-master01~03的VIP，不占用物理资源 主机节点名称 IP CPU核心数 内存大小 磁盘大小 k8s-master-vip 192.168.43.182 / / / k8s-master01 192.168.43.183 2 2G 40G k8s-master02 192.168.43.184 2 2G 40G k8s-master03 192.168.43.185 2 2G 40G k8s-node01 192.168.43.186 2 2G 40G k8s-node02 192.168.43.187 2 2G 40G 操作步骤 标题后小括号注释表明操作范围：\nALL 所有节点（k8s-master01/k8s-master02/k8s-master03/k8s-node01/k9s-node02）执行 Master 只需要在master节点（k8s-master01/k8s-master02/k8s-master03）执行 Node 只需要在node节点（k8s-node01/k8s-node02）执行 已标注的个别命令只需要在某一台机器执行，会在操作前说明 未标注的会在操作时说明 使用cat \u003c\u003c \"EOF\" \u003e\u003e file或cat \u003e\u003e file \u003c\u003c \"EOF\"添加文件内容注意cat后面的EOF一定要加上双引号（标准输入的），否则不会保留输入时的缩进格式而且会直接解析输入时的变量，进而造成文件可读性差甚至不可用；同时注意文件的\u003e重写与\u003e\u003e追加。虽然单独转义输入时的变量也能避免变量被解析，但是不推荐，漏转义会造成不必要的麻烦。\n准备工作(ALL) 添加主机信息、关闭防火墙、关闭swap、关闭SELinux、dnsmasq、NetworkManager\n# 添加主机信息 cat \u003c\u003c \"EOF\" \u003e\u003e /etc/hosts 192.168.43.182 k8s-master-vip 192.168.43.183 k8s-master01 192.168.43.184 k8s-master02 192.168.43.185 k8s-master03 192.168.43.186 k8s-node01 192.168.43.187 k8s-node02 EOF # 关闭防火墙、dnsmasq、NetworkManager，--now参数表示关闭服务并移除开机自启 # 这些服务是否可以关闭视情况而定，本文是虚拟机实践，没有用到这些服务 systemctl disable --now firewalld systemctl disable --now dnsmasq systemctl disable --now NetworkManager # 关闭swap，并注释fstab文件swap所在行 swapoff -a sed -i '/swap/s/^\\(.*\\)$/#\\1/g' /etc/fstab # 关闭SELinux，并更改selinux配置文件 setenforce 0 sed -i \"s/=enforcing/=disabled/g\" /etc/selinux/config 值得注意的是/etc/sysconfig/selinux文件是/etc/selinux/config文件的软连接，用sed -i命令修改软连接文件会破坏软连接属性，将/etc/sysconfig/selinux变为一个独立的文件，即使该文件被修改了，但源文件/etc/selinux/config配置是没变的。此外，使用vim等编辑器编辑源文件或链接文件（编辑模式不会修改文件属性）修改也可以。软链接原理可参考博客：LINUX之INODE详解\n必要操作(ALL) # 默认的yum源太慢，更新为阿里源，同时用sed命令删除文件中不需要的两个URL的行 curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo sed -i -e '/mirrors.cloud.aliyuncs.com/d' -e '/mirrors.aliyuncs.com/d' /etc/yum.repos.d/CentOS-Base.repo # 安装常用工具包 yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y # 配置阿里Kubernetes源，如果提示gpg文件有问题，可以改为gpgcheck=0，并把后三行删除（仅限测试环境使用） cat \u003c /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 配置ntpdate，同步服务器时间 rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm yum install ntpdate -y # 同步时区和时间 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime echo 'Asia/Shanghai' \u003e/etc/timezone ntpdate time2.aliyun.com # 可以加入计划任务，保证集群时钟是一致的 # /var/spool/cron/root文件也是crontab -e写入的文件 # crontab执行日志查看可用：tail -f /var/log/cron cat \u003c\u003c \"EOF\" \u003e\u003e /var/spool/cron/root */5 * * * * /usr/sbin/ntpdate time2.aliyun.com EOF # 保证文件句柄不会限制集群的可持续发展，配置limits ulimit -SHn 65500 cat \u003c\u003c \"EOF\" \u003e\u003e /etc/security/limits.conf * soft nofile 65500 * hard nofile 65500 * soft nproc 65500 * hard nproc 65500 * soft memlock unlimited * hard memlock unlimited EOF # 配置免密登录，k8s-master01到其他节点 # 生成密钥对（在k8s-master01节点配置即可） ssh-keygen -t rsa # 拷贝公钥到其他节点，首次需要认证一下各个节点的root密码，以后就可以免密ssh到其他节点 for i in k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done # 克隆二进制仓库文件（k8s-master01上操作即可） cd root;git clone https://gitee.com/deemoprobe/k8s-ha-install.git cd k8s-ha-install;git branch -a * master remotes/origin/HEAD -\u003e origin/master remotes/origin/manual-installation remotes/origin/manual-installation-v1.16.x remotes/origin/manual-installation-v1.17.x remotes/origin/manual-installation-v1.18.x remotes/origin/manual-installation-v1.19.x remotes/origin/manual-installation-v1.20.x remotes/origin/manual-installation-v1.20.x-csi-hostpath remotes/origin/manual-installation-v1.21.x remotes/origin/manual-installation-v1.22.x remotes/origin/manual-installation-v1.23.x remotes/origin/master # 可以切换到需要版本的分支中获取配置文件 git checkout manual-installation-v1.22.x # 所有节点系统升级 yum update --exclude=kernel* -y 升级内核，4.17以下的内核cgroup存在内存泄漏的BUG，具体分析过程浏览器搜Kubernetes集群为什么要升级内核会有很多文章讲解\n内核备用下载（建议下载到本地后上传到服务器，尽量不用wget）：\nkernel-ml-devel-4.19.12-1.el7.elrepo.x86_64.rpm kernel-ml-4.19.12-1.el7.elrepo.x86_64.rpm # 下载4.19版本内核，如果无法下载，可以用上面提供的备用下载 cd /root wget http://193.49.22.109/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-4.19.12-1.el7.elrepo.x86_64.rpm wget http://193.49.22.109/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-4.19.12-1.el7.elrepo.x86_64.rpm # 可以在k8s-master01节点下载后，免密传到其他节点 for i in k8s-master02 k8s-master03 k8s-node01 k8s-node02;do scp kernel-ml-* $i:/root;done # 所有节点安装内核 cd /root \u0026\u0026 yum localinstall -y kernel-ml* # 所有节点更改内核启动顺序 grub2-set-default 0 \u0026\u0026 grub2-mkconfig -o /etc/grub2.cfg grubby --args=\"user_namespace.enable=1\" --update-kernel=\"$(grubby --default-kernel)\" # 查看默认内核，并重启节点 grubby --default-kernel reboot # 确认内核版本 uname -a # （可选）删除老版本的内核，避免以后被升级取代默认的开机4.19内核 rpm -qa | grep kernel yum remove -y kernel-3* # 升级系统软件包（如果跳过内核升级加参数 --exclude=kernel*） yum update -y # 安装IPVS相关工具，由于IPVS在资源消耗和性能上均已明显优于iptables，所以推荐开启 # 具体原因可参考官网介绍 https://kubernetes.io/zh/blog/2018/07/09/ipvs-based-in-cluster-load-balancing-deep-dive/ yum install ipvsadm ipset sysstat conntrack libseccomp -y # 加载模块，最后一条4.18及以下内核使用nf_conntrack_ipv4，4.19已改为nf_conntrack modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack # 编写参数文件 cat \u003c\u003c \"EOF\" \u003e /etc/modules-load.d/ipvs.conf ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp ip_vs_sh nf_conntrack ip_tables ip_set xt_set ipt_set ipt_rpfilter ipt_REJECT ipip EOF # systemd-modules-load加入开机自启 systemctl enable --now systemd-modules-load # 自定义内核参数优化配置文件 cat \u003c\u003c \"EOF\" \u003e /etc/sysctl.d/kubernetes.conf net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 fs.may_detach_mounts = 1 net.ipv4.conf.all.route_localnet = 1 vm.overcommit_memory=1 vm.panic_on_oom=0 fs.inotify.max_user_watches=89100 fs.file-max=52706963 fs.nr_open=52706963 net.netfilter.nf_conntrack_max=2310720 net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_keepalive_probes = 3 net.ipv4.tcp_keepalive_intvl =15 net.ipv4.tcp_max_tw_buckets = 36000 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_max_orphans = 327680 net.ipv4.tcp_orphan_retries = 3 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 16384 net.ipv4.ip_conntrack_max = 65536 net.ipv4.tcp_max_syn_backlog = 16384 net.ipv4.tcp_timestamps = 0 net.core.somaxconn = 16384 EOF # 加载 sysctl --system # 重启查看IPVS模块是否依旧加载 reboot lsmod | grep -e ip_vs -e nf_conntrack 保证每台服务器中IPVS加载成功，以k8s-master01为例，如图： 部署Docker(ALL) # 卸载已存在docker，新机器的话这步可以忽略 yum remove -y docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine yum remove -y docker-ce docker-ce-cli containerd.io # 配置阿里docker源 yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 安装最新版本docker yum install docker-ce docker-ce-cli containerd.io -y # （可选）如果想要安装指定版本docker，先查询一下。安装指定版本，例如20.10.9-3.el7 yum list docker-ce docker-ce-cli --showduplicates | grep \"^doc\" | sort -r yum install docker-ce-20.10.9-3.el7 docker-ce-cli-20.10.9-3.el7 containerd.io -y # 加入开机启动并启动 systemctl enable docker systemctl start docker # 测试运行hello-world镜像并查看docker版本信息 docker run hello-world docker version # 配置阿里docker镜像加速器，阿里云(登录账号--\u003e点击管理控制台--\u003e搜索容器镜像服务--\u003e镜像工具--\u003e镜像加速器--\u003e复制加速器地址) # docker文件驱动改成 systemd cat \u003c /etc/docker/daemon.json { \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"registry-mirrors\": [\"https://ynirk4k5.mirror.aliyuncs.com\"] } EOF # 重启docker systemctl restart docker # 如果启动失败,强制加载再启动试试 systemctl reset-failed docker systemctl restart docker # 查看docker配置信息 docker info docker info | grep Driver 安装kubernetes(ALL) 一般kubectl在master节点安装即可,node节点装不装均可\n# 查看可以安装的版本号 yum list kubeadm --showduplicates | sort -r # 不指定版本的话默认安装最新版本安装 yum install -y kubelet kubeadm kubectl # （可选）指定版本进行安装，如1.23.0 yum install -y kubelet-1.23.0 kubeadm-1.23.0 kubectl-1.23.0 # 配置pause镜像仓库，默认的gcr.io国内无法访问，可以使用阿里仓库 cat \u003c\u003c \"EOF\" \u003e /etc/sysconfig/kubelet KUBELET_EXTRA_ARGS=\"--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5\" EOF # 加入开机启动并启动，此处启动失败不必排查，待初始化完成kubelet会自动恢复正常 systemctl enable --now kubelet 高可用组件安装(Master) # 所有master节点安装Keepalived和haproxy yum install keepalived haproxy -y # 为所有master节点添加haproxy配置，配置都一样，检查最后三行主机名和IP地址对应上就行 mkdir /etc/haproxy cat \u003c\u003c \"EOF\" \u003e /etc/haproxy/haproxy.cfg global maxconn 2000 ulimit-n 16384 log 127.0.0.1 local0 err stats timeout 30s defaults log global mode http option httplog timeout connect 5000 timeout client 50000 timeout server 50000 timeout http-request 15s timeout http-keep-alive 15s frontend monitor-in bind *:33305 mode http option httplog monitor-uri /monitor frontend k8s-master bind 0.0.0.0:16443 bind 127.0.0.1:16443 mode tcp option tcplog tcp-request inspect-delay 5s default_backend k8s-master backend k8s-master mode tcp option tcplog option tcp-check balance roundrobin default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100 server k8s-master01 192.168.43.183:6443 check server k8s-master02 192.168.43.184:6443 check server k8s-master03 192.168.43.185:6443 check EOF # keepalived配置不一样，注意区分网卡名、IP地址和虚拟IP地址 # 检查服务器网卡名 ip a 或 ifconfig # k8s-master01 Keepalived配置 mkdir /etc/keepalived cat \u003c\u003c \"EOF\" \u003e /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id LVS_DEVEL script_user root enable_script_security } vrrp_script chk_apiserver { script \"/etc/keepalived/check_apiserver.sh\" interval 5 weight -5 fall 2 rise 1 } vrrp_instance VI_1 { state MASTER interface ens33 mcast_src_ip 192.168.43.183 virtual_router_id 51 priority 101 advert_int 2 authentication { auth_type PASS auth_pass K8SHA_KA_AUTH } virtual_ipaddress { 192.168.43.182 } track_script { chk_apiserver } } EOF # k8s-master02 Keepalived配置 mkdir /etc/keepalived cat \u003c\u003c \"EOF\" \u003e /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id LVS_DEVEL script_user root enable_script_security } vrrp_script chk_apiserver { script \"/etc/keepalived/check_apiserver.sh\" interval 5 weight -5 fall 2 rise 1 } vrrp_instance VI_1 { state BACKUP interface ens33 mcast_src_ip 192.168.43.184 virtual_router_id 51 priority 100 advert_int 2 authentication { auth_type PASS auth_pass K8SHA_KA_AUTH } virtual_ipaddress { 192.168.43.182 } track_script { chk_apiserver } } EOF # k8s-master03 Keepalived配置 mkdir /etc/keepalived cat \u003c\u003c \"EOF\" \u003e /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id LVS_DEVEL script_user root enable_script_security } vrrp_script chk_apiserver { script \"/etc/keepalived/check_apiserver.sh\" interval 5 weight -5 fall 2 rise 1 } vrrp_instance VI_1 { state BACKUP interface ens33 mcast_src_ip 192.168.43.185 virtual_router_id 51 priority 100 advert_int 2 authentication { auth_type PASS auth_pass K8SHA_KA_AUTH } virtual_ipaddress { 192.168.43.182 } track_script { chk_apiserver } } EOF # 所有master节点配置Keepalived健康检查脚本 cat \u003c\u003c \"EOF\" \u003e /etc/keepalived/check_apiserver.sh #!/bin/bash err=0 for k in $(seq 1 3) do check_code=$(pgrep haproxy) if [[ $check_code == \"\" ]]; then err=$(expr $err + 1) sleep 1 continue else err=0 break fi done if [[ $err != \"0\" ]]; then echo \"systemctl stop keepalived\" /usr/bin/systemctl stop keepalived exit 1 else exit 0 fi EOF # 赋予可执行权限 chmod +x /etc/keepalived/check_apiserver.sh # 启动haproxy和Keepalived并加入开机启动 systemctl start haproxy systemctl start keepalived systemctl enable haproxy systemctl enable keepalived # 测试一波 telnet k8s-master-vip 16443 ping k8s-master-vip 部署k8s-master(k8s-master01) 在k8s-master01节点上执行，个别步骤在所有master节点执行，已另行说明，没说明的均是在k8s-master01执行。\n# 创建初始化文件，注意版本号和IP对应上 cat \u003c\u003c \"EOF\" \u003e kubeadm-config.yaml apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: 7t2weq.bjbawausm0jaxury ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 192.168.43.183 # API通知地址，设置为初始化IP即可 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock # docker作为Container Runtime # criSocket: /run/containerd/containerd.sock # containerd作为Container Runtime name: k8s-master01 # 初始化节点名 taints: - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: certSANs: - 192.168.43.182 timeoutForControlPlane: 4m0s # 初始化超时时间 apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controlPlaneEndpoint: 192.168.43.182:16443 # 如果不是高可用集群，则为6443 controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers # 国内地址 kind: ClusterConfiguration kubernetesVersion: v1.23.0 # 需与kubeadm version版本号保持一致 networking: dnsDomain: cluster.local podSubnet: 172.16.0.0/12 # 不可与其他IP段冲突 serviceSubnet: 10.96.0.0/12 # 不可与其他IP段冲突 scheduler: {} EOF # 更新初始化文件 kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml # 将new.yaml复制到其他master节点上 for i in k8s-master02 k8s-master03;do scp new.yaml $i:/root/;done # 镜像预下载，节省集群初始化的时间（这一步在所有master节点上执行） kubeadm config images pull --config /root/new.yaml # 执行结果如下 [config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.23.0 [config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.23.0 [config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.23.0 [config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.23.0 [config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 [config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.1-0 [config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.6 # master01初始化，初始化完成后，加入其他节点即可 kubeadm init --config /root/new.yaml --upload-certs # 初始化如果失败，可用下面命令清除初始化信息，然后再次尝试初始化 kubeadm reset -f ; ipvsadm --clear ; rm -rf ~/.kube # 初始化成功类似于下面输出，保存好这些信息 ... Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of the control-plane node running the following command on each as root: kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury \\ --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b \\ --control-plane --certificate-key 9a2e86718fceba001c96e503e9df47db3a645d4917bf783decaea9c5d0a726ed Please note that the certificate-key gives access to cluster sensitive data, keep it secret! As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use \"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward. Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury \\ --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b # 按照提示，如果你是普通用户在操作，执行一下下面几条 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # 如果是root用户在操作初始化，执行下面一条即可 export KUBECONFIG=/etc/kubernetes/admin.conf # 查看docker镜像,可以看到kube..和etcd等镜像 docker images # Token过期后生成新的token（没提示过期下面两步就不用管了） kubeadm token create --print-join-command # Master需要生成--certificate-key kubeadm init phase upload-certs --upload-certs 其他节点加入集群 其他master节点加入k8s-master01\n# 根据kubeadm init提示的token kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury \\ --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b \\ --control-plane --certificate-key 9a2e86718fceba001c96e503e9df47db3a645d4917bf783decaea9c5d0a726ed node节点加入k8s-master01\n# 根据kubeadm init提示的token kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury \\ --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b # master01上查看加入后的节点信息，因为还未配置CNI插件，所以node之间通信还未打通 [root@k8s-master01 ~]# kubectl get no NAME STATUS ROLES AGE VERSION k8s-master01 NotReady control-plane,master 19m v1.23.0 k8s-master02 NotReady control-plane,master 3m39s v1.23.0 k8s-master03 NotReady control-plane,master 3m35s v1.23.0 k8s-node01 NotReady 2m21s v1.23.0 k8s-node02 NotReady 2m21s v1.23.0 配置calico网络 在k8s-master01节点上执行\n网络方案也可以选择其他(例如：flannel等)\n# 先把所需的配置文件从GitHub拉下来 git clone https://github.com/deemoprobe/k8s-ha-install.git # 切换到1.23分支并进入calico文件夹 cd /root/k8s-ha-install \u0026\u0026 git checkout manual-installation-v1.23.x \u0026\u0026 cd calico/ # 替换一下POD网段 POD_SUBNET=`cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr= | awk -F= '{print $NF}'` sed -i \"s#POD_CIDR#${POD_SUBNET}#g\" calico.yaml # 应用calico插件 kubectl apply -f calico.yaml # 集群节点均已处于Ready状态 [root@k8s-master01 calico]# kubectl get no NAME STATUS ROLES AGE VERSION k8s-master01 Ready control-plane,master 29m v1.23.0 k8s-master02 Ready control-plane,master 13m v1.23.0 k8s-master03 Ready control-plane,master 13m v1.23.0 k8s-node01 Ready 11m v1.23.0 k8s-node02 Ready 11m v1.23.0 # 查看calico Pod是否都正常 kubectl get pod -A # 如果不正常，可以排查一下，一般是镜像拉取问题，多等待几分钟即可，也可以根据报错简单处理一下 kubectl describe pod XXX -n kube-system # 比如我这里有个pod处于pending状态，查看一下原因 [root@k8s-master01 calico]# kubectl get pod -A NAMESPACE NAME READY STATUS RESTARTS AGE ... kube-system calico-typha-8445487f56-hx8w9 1/1 Running 0 11m kube-system calico-typha-8445487f56-mh6tp 0/1 Pending 0 11m kube-system calico-typha-8445487f56-pxthb 1/1 Running 0 11m ... # 可以看到提示说2个node节点无法提供足量的pod端口分配需求，而且提示master节点设置了污点 [root@k8s-master01 calico]# kubectl describe pod calico-typha-8445487f56-mh6tp -n kube-system ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 11m default-scheduler 0/5 nodes are available: 2 node(s) had taint {node.kubernetes.io/not-ready: }, that the pod didn't tolerate, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate. Warning FailedScheduling 10m default-scheduler 0/5 nodes are available: 1 node(s) didn't have free ports for the requested pod ports, 1 node(s) had taint {node.kubernetes.io/not-ready: }, that the pod didn't tolerate, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate. Warning FailedScheduling 10m default-scheduler 0/5 nodes are available: 2 node(s) didn't have free ports for the requested pod ports, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate. Warning FailedScheduling 8m24s (x1 over 9m24s) default-scheduler 0/5 nodes are available: 2 node(s) didn't have free ports for the requested pod ports, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate.' # 确认一下，可以看到三个master节点打上了不可调度pod的污点 [root@k8s-master01 calico]# for i in k8s-master01 k8s-master02 k8s-master03;do kubectl describe node $i | grep -i taint;done Taints: node-role.kubernetes.io/master:NoSchedule Taints: node-role.kubernetes.io/master:NoSchedule Taints: node-role.kubernetes.io/master:NoSchedule # 由于是练习环境，我就把不可调度的污点取消了，如果是生产环境，建议扩容node工作节点来实现足量的端口分配 [root@k8s-master01 calico]# for i in k8s-master01 k8s-master02 k8s-master03;do kubectl taint node $i node-role.kubernetes.io/master:NoSchedule-;done node/k8s-master01 untainted node/k8s-master02 untainted node/k8s-master03 untainted # 污点成功取消 [root@k8s-master01 calico]# for i in k8s-master01 k8s-master02 k8s-master03;do kubectl describe node $i | grep -i taint;done Taints: Taints: Taints: # 再查看刚才处于pending的pod发现已经处于running状态了 [root@k8s-master01 calico]# kubectl get po -A | grep calico-typha-8445487f56-mh6tp kube-system calico-typha-8445487f56-mh6tp 1/1 Running 0 23m 部署Metrics 在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率。\n# 将Master01节点的front-proxy-ca.crt复制到所有Node节点 [root@k8s-master01 calico]# for i in k8s-node01 k8s-node02;do scp /etc/kubernetes/pki/front-proxy-ca.crt $i:/etc/kubernetes/pki/front-proxy-ca.crt;done front-proxy-ca.crt 100% 1115 593.4KB/s 00:00 front-proxy-ca.crt 100% 1115 1.4MB/s 00:00 # 安装metrics server [root@k8s-master01 calico]# cd /root/k8s-ha-install/kubeadm-metrics-server [root@k8s-master01 kubeadm-metrics-server]# kubectl apply -f comp.yaml serviceaccount/metrics-server created clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created clusterrole.rbac.authorization.k8s.io/system:metrics-server created rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created service/metrics-server created deployment.apps/metrics-server created apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created # 查看运行状态 [root@k8s-master01 kubeadm-metrics-server]# kubectl get po -A | grep metrics kube-system metrics-server-5cf8885b66-2nnb6 1/1 Running 0 68s # 部署后便可以查看指标了 [root@k8s-master01 kubeadm-metrics-server]# kubectl top node NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% k8s-master01 177m 8% 1196Mi 64% k8s-master02 153m 7% 1101Mi 58% k8s-master03 163m 8% 1102Mi 58% k8s-node01 88m 4% 848Mi 45% k8s-node02 85m 4% 842Mi 45% [root@k8s-master01 kubeadm-metrics-server]# kubectl top po NAME CPU(cores) MEMORY(bytes) nginx-85b98978db-7mn6r 0m 3Mi 部署Dashboard Dashboard是一个展示Kubernetes集群资源和Pod日志，甚至可以执行容器命令的web控制台。\n# 直接部署即可 [root@k8s-master01 kubeadm-metrics-server]# cd /root/k8s-ha-install/dashboard/ [root@k8s-master01 dashboard]# ls dashboard-user.yaml dashboard.yaml [root@k8s-master01 dashboard]# kubectl apply -f . serviceaccount/admin-user created clusterrolebinding.rbac.authorization.k8s.io/admin-user created namespace/kubernetes-dashboard created serviceaccount/kubernetes-dashboard created service/kubernetes-dashboard created secret/kubernetes-dashboard-certs created secret/kubernetes-dashboard-csrf created secret/kubernetes-dashboard-key-holder created configmap/kubernetes-dashboard-settings created role.rbac.authorization.k8s.io/kubernetes-dashboard created clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created deployment.apps/kubernetes-dashboard created service/dashboard-metrics-scraper created deployment.apps/dashboard-metrics-scraper created # 查看dashboard端口，默认是NodePort模式，访问集群内任意节点的31073端口即可 [root@k8s-master01 dashboard]# kubectl get svc -owide -A | grep dash kubernetes-dashboard dashboard-metrics-scraper ClusterIP 10.105.172.8 8000/TCP 19m k8s-app=dashboard-metrics-scraper kubernetes-dashboard kubernetes-dashboard NodePort 10.99.148.159 443:31073/TCP 19m k8s-app=kubernetes-dashboard 访问dashboard：https://集群内任意节点IP:31073\n发现提示隐私设置错误的问题，如图：\n在Chrome浏览器启动参数加入--test-type --ignore-certificate-errors，然后再访问就没有这个安全提示了\n# 获取登陆令牌（token） [root@k8s-master01 dashboard]# kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}') Name: admin-user-token-mwnfs Namespace: kube-system Labels: Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 29584392-1cbd-4d5c-91af-9dd4703008aa Type: kubernetes.io/service-account-token Data ==== ca.crt: 1099 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IjRyZlh6Ukxta0FlajlHREF5ei1mdl8tZmR6ekwteV9fVEIwalQtejRwUk0ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLW13bmZzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIyOTU4NDM5Mi0xY2JkLTRkNWMtOTFhZi05ZGQ0NzAzMDA4YWEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pMBMkLAP2AoymIXJC7H47IPu3avdBWPYSZfvjRME7lEQAnbe-SM-yrTFGPzcsJQC3O9gPDvXgIZ1x1tQUtQhc_333GtDMj_VL9oEZxYiOdd578CnBiFmF0BWVX06pAzONgKbguamMD8XEPAvKt4mnlDUr7WCeQJZf_juXKdl7ZOBtrM5Zae0UQHFG6juKLmFP-XxIgoDVIPhcxeAH1ktOHM9Fk1M831hywL1SL2OLHiN52wGLT4WuYrP2iUbJkNpt2PYitSp3iNuh7rESL4Ur7lmFQkLZa9e5vNMCc1wTwOAWvaW4P5TbxtfI_ng4NK_avquiXJY-67D77G-8WKzWg 集群优化(可选) Docker可在/etc/docker/daemon.json自定义优化配置，所有配置可见：官方docker configuration，docker常用优化配置见下方注释说明。\n# 优化docker配置 # /etc/docker/daemon.json文件，按需配置，不需要全部都照抄，使用时删除注释，因为JSON文件不支持注释 { \"exec-opts\": [\"native.cgroupdriver=systemd\"], # cgroups驱动 \"registry-mirrors\": [\"https://ynirk4k5.mirror.aliyuncs.com\"], # 镜像加速器地址 \"allow-nondistributable-artifacts\": [], \"api-cors-header\": \"\", \"authorization-plugins\": [], \"bip\": \"\", \"bridge\": \"\", \"cgroup-parent\": \"\", \"cluster-advertise\": \"\", \"cluster-store\": \"\", \"cluster-store-opts\": {}, \"containerd\": \"/run/containerd/containerd.sock\", \"containerd-namespace\": \"docker\", \"data-root\": \"\", # 数据根目录，大量docker镜像可能会占用较大存储，可以设置系统盘外的挂载盘 \"debug\": true, \"default-address-pools\": [ { \"base\": \"172.30.0.0/16\", \"size\": 24 }, { \"base\": \"172.31.0.0/16\", \"size\": 24 } ], \"default-cgroupns-mode\": \"private\", \"default-gateway\": \"\", \"default-gateway-v6\": \"\", \"default-runtime\": \"runc\", \"default-shm-size\": \"64M\", \"default-ulimits\": { \"nofile\": { \"Hard\": 64000, \"Name\": \"nofile\", \"Soft\": 64000 } }, \"dns\": [], \"dns-opts\": [], \"dns-search\": [], \"exec-root\": \"\", \"experimental\": false, \"features\": {}, \"fixed-cidr\": \"\", \"fixed-cidr-v6\": \"\", \"group\": \"\", \"hosts\": [], \"icc\": false, \"init\": false, \"init-path\": \"/usr/libexec/docker-init\", \"insecure-registries\": [], \"ip\": \"0.0.0.0\", \"ip-forward\": false, \"ip-masq\": false, \"iptables\": false, \"ip6tables\": false, \"ipv6\": false, \"labels\": [], \"live-restore\": true, # docker进程宕机时容器依然保持存活 \"log-driver\": \"json-file\", # 日志格式 \"log-level\": \"\", # 日志级别 \"log-opts\": { # 日志优化 \"cache-disabled\": \"false\", \"cache-max-file\": \"5\", \"cache-max-size\": \"20m\", \"cache-compress\": \"true\", \"env\": \"os,customer\", \"labels\": \"somelabel\", \"max-file\": \"5\", # 最大日志数量 \"max-size\": \"10m\" # 保存的最大日志大小 }, \"max-concurrent-downloads\": 3, # pull下载并发数 \"max-concurrent-uploads\": 5, # push上传并发数 \"max-download-attempts\": 5, \"mtu\": 0, \"no-new-privileges\": false, \"node-generic-resources\": [ \"NVIDIA-GPU=UUID1\", \"NVIDIA-GPU=UUID2\" ], \"oom-score-adjust\": -500, \"pidfile\": \"\", \"raw-logs\": false, \"runtimes\": { \"cc-runtime\": { \"path\": \"/usr/bin/cc-runtime\" }, \"custom\": { \"path\": \"/usr/local/bin/my-runc-replacement\", \"runtimeArgs\": [ \"--debug\" ] } }, \"seccomp-profile\": \"\", \"selinux-enabled\": false, \"shutdown-timeout\": 15, \"storage-driver\": \"\", \"storage-opts\": [], \"swarm-default-advertise-addr\": \"\", \"tls\": true, \"tlscacert\": \"\", \"tlscert\": \"\", \"tlskey\": \"\", \"tlsverify\": true, \"userland-proxy\": false, \"userland-proxy-path\": \"/usr/libexec/docker-proxy\", \"userns-remap\": \"\" } # 无注释版 { \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"registry-mirrors\": [\"https://ynirk4k5.mirror.aliyuncs.com\"], \"containerd-namespace\": \"docker\", \"data-root\": \"\", \"debug\": true, \"default-cgroupns-mode\": \"private\", \"default-gateway\": \"\", \"default-gateway-v6\": \"\", \"default-runtime\": \"runc\", \"default-shm-size\": \"64M\", \"default-ulimits\": { \"nofile\": { \"Hard\": 64000, \"Name\": \"nofile\", \"Soft\": 64000 } }, \"init-path\": \"/usr/libexec/docker-init\", \"live-restore\": true, \"log-driver\": \"json-file\", \"log-level\": \"\", \"log-opts\": { \"cache-disabled\": \"false\", \"cache-max-file\": \"5\", \"cache-max-size\": \"20m\", \"cache-compress\": \"true\", \"env\": \"os,customer\", \"labels\": \"somelabel\", \"max-file\": \"5\", \"max-size\": \"10m\" }, \"max-concurrent-downloads\": 3, \"max-concurrent-uploads\": 5, \"max-download-attempts\": 5, \"mtu\": 0, \"no-new-privileges\": false, \"oom-score-adjust\": -500, \"pidfile\": \"\", \"raw-logs\": false, \"runtimes\": { \"cc-runtime\": { \"path\": \"/usr/bin/cc-runtime\" }, \"custom\": { \"path\": \"/usr/local/bin/my-runc-replacement\", \"runtimeArgs\": [ \"--debug\" ] } }, \"seccomp-profile\": \"\", \"selinux-enabled\": false, \"shutdown-timeout\": 15, \"storage-driver\": \"\", \"storage-opts\": [], \"swarm-default-advertise-addr\": \"\", \"userland-proxy-path\": \"/usr/libexec/docker-proxy\", \"userns-remap\": \"\" } # 设置证书有效期 [root@k8s-master01 ~]# vim /usr/lib/systemd/system/kube-controller-manager.service ... # 加入下面配置 --experimental-cluster-signing-duration=876000h0m0s ... [root@k8s-master01 ~]# systemctl daemon-reload [root@k8s-master01 ~]# systemctl restart kube-controller-manager # kubelet优化加密算法，默认的算法容易被漏洞扫描；增长镜像下载周期，避免有些大镜像未下载完成就被动死亡退出 # --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 # --image-pull-progress-deadline=30m [root@k8s-master01 ~]# vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf ... # 下面这行中KUBELET_EXTRA_ARGS=后加入配置 Environment=\"KUBELET_EXTRA_ARGS=--tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 --image-pull-progress-deadline=30m\" ... # 集群配置优化，详见https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/ [root@k8s-master01 ~]# vim /etc/kubernetes/kubelet-conf.yml # 文件中添加如下配置 rotateServerCertificates: true allowedUnsafeSysctls: # 允许在修改内核参数，此操作按情况选择，用不到就不用设置 - \"net.core*\" - \"net.ipv4.*\" kubeReserved: # 为Kubernetes集群守护进程组件预留资源，例如：kubelet、Runtime等 cpu: \"100m\" memory: 100Mi ephemeral-storage: 1Gi systemReserved: # 为系统守护进程预留资源，例如：sshd、cron等 cpu: \"100m\" memory: 100Mi ephemeral-storage: 1Gi # 更改kube-proxy模式为ipvs [root@k8s-master01 dashboard]# kubectl edit cm kube-proxy -n kube-system mode: \"ipvs\" # 更新kube-proxy的pod [root@k8s-master01 dashboard]# kubectl patch daemonset kube-proxy -p \"{\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"date\\\":\\\"`date +'%s'`\\\"}}}}}\" -n kube-system daemonset.apps/kube-proxy patched # 验证 [root@k8s-master01 dashboard]# curl 127.0.0.1:10249/proxyMode ipvs # 为集群节点打标签，删除标签把 = 换成 - 即可 kubectl label nodes k8s-node01 node-role.kubernetes.io/node= kubectl label nodes k8s-node02 node-role.kubernetes.io/node= kubectl label nodes k8s-master01 node-role.kubernetes.io/master= kubectl label nodes k8s-master02 node-role.kubernetes.io/master= kubectl label nodes k8s-master03 node-role.kubernetes.io/master= # 添加标签后查看集群状态 [root@k8s-master01 ~]# kubectl get node NAME STATUS ROLES AGE VERSION k8s-master01 Ready master 100m v1.23.0 k8s-master02 Ready master 100m v1.23.0 k8s-master03 Ready master 100m v1.23.0 k8s-node01 Ready node 100m v1.23.0 k8s-node02 Ready node 100m v1.23.0 生产环境建议ETCD集群和Kubernetes集群分离，而且使用高性能数据盘存储数据，根据情况决定是否将Master节点也作为Pod调度节点。\n测试集群 # 测试namespace kubectl get namespace kubectl create namespace test kubectl get namespace kubectl delete namespace test # 创建nginx实例并开放端口 kubectl create deployment nginx --image=nginx kubectl expose deployment nginx --port=80 --type=NodePort # 查看调度状态和端口号 [root@k8s-master01 calico]# kubectl get pod,svc -owide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod/nginx-85b98978db-7mn6r 1/1 Running 0 2m16s 172.27.14.193 k8s-master02 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service/kubernetes ClusterIP 10.96.0.1 443/TCP 59m service/nginx NodePort 10.104.33.99 80:31720/TCP 2m6s app=nginx 可见调度到了k8s-master02（IP地址是192.168.43.184）上，对应的NodePort为31720\n在浏览器输入http://192.168.43.184:31720/ 访问nginx，访问结果如图\n至此，基于kubeadm的Kubernetes高可用集群部署并验证成功。\n",
  "wordCount" : "7824",
  "inLanguage": "en",
  "image":"https://deemoprobe.github.io/img/kubernetes.png","datePublished": "2023-04-29T14:12:14+08:00",
  "dateModified": "2023-04-29T14:12:14+08:00",
  "author":[{
    "@type": "Person",
    "name": "deemoprobe"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://deemoprobe.github.io/posts/tech/kubernetes/kuberneteskubeadminstallation-ha/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "William's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://deemoprobe.github.io/img/favicon/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    (function () {
        let  arr,reg = new RegExp("(^| )"+"change-themes"+"=([^;]*)(;|$)");
        if(arr = document.cookie.match(reg)) {
        } else {
            if (new Date().getHours() >= 19 || new Date().getHours() < 6) {
                document.body.classList.add('dark');
                localStorage.setItem("pref-theme", 'dark');
            } else {
                document.body.classList.remove('dark');
                localStorage.setItem("pref-theme", 'light');
            }
        }
    })()

    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://deemoprobe.github.io/" accesskey="h" title="Background (Alt + H)">Background</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                         fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                         stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://deemoprobe.github.io/" title="🏠 主页">
                <span>🏠 主页</span>
                </a>
            </li>
            <li>
                <a href="https://deemoprobe.github.io/tags" title="🎨 标签">
                <span>🎨 标签</span>
                </a>
            </li>
            <li>
                <a href="https://deemoprobe.github.io/archives/" title="📈 归档">
                <span>📈 归档</span>
                </a>
            </li>
            <li>
                <a href="https://deemoprobe.github.io/tools" title="🪁 工具">
                <span>🪁 工具</span>
                </a>
            </li>
            <li>
                <a href="https://wangchujiang.com/linux-command/" title="🐧 命令">
                <span>🐧 命令</span>
                </a>
            </li>
            <li>
                <a href="https://deemoprobe.github.io/search" title="🔍 搜索 (Alt &#43; /)" accesskey=/>
                <span>🔍 搜索</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main page">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }
</style>

<article class="post-single">
    <div id="single-content">
        <header class="post-header">
            
            <h1 class="post-title">
                KubernetesKubeadmInstallation HA
            </h1>
            <div class="post-description">
                kubeadm方式部署kubernetes高可用集群
            </div>
            <div class="post-meta">

<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2023-04-29
            &nbsp;&nbsp;
        </span>
    </span>
    
    
    
    
    
    
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>7824字
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>16分钟
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>deemoprobe
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="https://deemoprobe.github.io/tags/kubernetes/" style="color: var(--secondary)!important;">kubernetes</a>
            </span>
        </span>
    </span>
</span>
<span style="opacity: 0.8;">
                    <span id="post_meta_style_7">
                        &nbsp;&nbsp;
                        <span class="fa fa-eye" ></span>
                        <span>
                            <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
                            &nbsp;&nbsp;
                        </span>
                    </span>
                    
                </span>

</div>
        </header> 
<figure class="entry-cover1"><img style="zoom:;" loading="lazy" src="https://deemoprobe.github.io/img/kubernetes.png" alt="">
    
</figure><aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">文章目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e7%8e%af%e5%a2%83%e8%af%b4%e6%98%8e" aria-label="环境说明">环境说明</a></li>
                <li>
                    <a href="#%e8%b5%84%e6%ba%90%e5%88%86%e9%85%8d" aria-label="资源分配">资源分配</a><ul>
                        
                <li>
                    <a href="#%e7%bd%91%e6%ae%b5%e5%88%92%e5%88%86" aria-label="网段划分">网段划分</a></li>
                <li>
                    <a href="#%e8%8a%82%e7%82%b9%e5%88%86%e9%85%8d" aria-label="节点分配">节点分配</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%93%8d%e4%bd%9c%e6%ad%a5%e9%aa%a4" aria-label="操作步骤">操作步骤</a><ul>
                        
                <li>
                    <a href="#%e5%87%86%e5%a4%87%e5%b7%a5%e4%bd%9call" aria-label="准备工作(ALL)">准备工作(ALL)</a></li>
                <li>
                    <a href="#%e5%bf%85%e8%a6%81%e6%93%8d%e4%bd%9call" aria-label="必要操作(ALL)">必要操作(ALL)</a></li>
                <li>
                    <a href="#%e9%83%a8%e7%bd%b2dockerall" aria-label="部署Docker(ALL)">部署Docker(ALL)</a></li>
                <li>
                    <a href="#%e5%ae%89%e8%a3%85kubernetesall" aria-label="安装kubernetes(ALL)">安装kubernetes(ALL)</a></li>
                <li>
                    <a href="#%e9%ab%98%e5%8f%af%e7%94%a8%e7%bb%84%e4%bb%b6%e5%ae%89%e8%a3%85master" aria-label="高可用组件安装(Master)">高可用组件安装(Master)</a></li>
                <li>
                    <a href="#%e9%83%a8%e7%bd%b2k8s-masterk8s-master01" aria-label="部署k8s-master(k8s-master01)">部署k8s-master(k8s-master01)</a></li>
                <li>
                    <a href="#%e5%85%b6%e4%bb%96%e8%8a%82%e7%82%b9%e5%8a%a0%e5%85%a5%e9%9b%86%e7%be%a4" aria-label="其他节点加入集群">其他节点加入集群</a></li>
                <li>
                    <a href="#%e9%85%8d%e7%bd%aecalico%e7%bd%91%e7%bb%9c" aria-label="配置calico网络">配置calico网络</a></li></ul>
                </li>
                <li>
                    <a href="#%e9%83%a8%e7%bd%b2metrics" aria-label="部署Metrics">部署Metrics</a></li>
                <li>
                    <a href="#%e9%83%a8%e7%bd%b2dashboard" aria-label="部署Dashboard">部署Dashboard</a></li>
                <li>
                    <a href="#%e9%9b%86%e7%be%a4%e4%bc%98%e5%8c%96%e5%8f%af%e9%80%89" aria-label="集群优化(可选)">集群优化(可选)</a></li>
                <li>
                    <a href="#%e6%b5%8b%e8%af%95%e9%9b%86%e7%be%a4" aria-label="测试集群">测试集群</a>
                </li>
            </ul>
        </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
        
        activeElement = elements[0];
        const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
        document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
    }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 &&
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
            const id = encodeURI(element.getAttribute('id')).toLowerCase();
            if (element === activeElement){
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
            } else {
                document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
            }
        })
    }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;
        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;
    }
</script>
        <div class="post-content"><h2 id="环境说明">环境说明<a hidden class="anchor" aria-hidden="true" href="#环境说明">#</a></h2>
<ul>
<li>宿主机系统：Windows 10</li>
<li>虚拟机版本：VMware® Workstation 16 Pro</li>
<li>IOS镜像版本：CentOS Linux release 7.9.2009</li>
<li>集群操作用户：root</li>
<li>Kubernetes版本：1.23.0</li>
<li>Etcd版本：3.5.1</li>
<li>Runtime：Docker 20.10</li>
</ul>
<p>CentOS7安装请参考博客文章：<a href="https://www.deemo.dev/linux/centos7install/"  target="_blank" rel="noopener" style="color:#42b983" ;>LINUX之VMWARE WORKSTATION安装CENTOS-7</a></p>
<h2 id="资源分配">资源分配<a hidden class="anchor" aria-hidden="true" href="#资源分配">#</a></h2>
<h3 id="网段划分">网段划分<a hidden class="anchor" aria-hidden="true" href="#网段划分">#</a></h3>
<p>Kubernetes集群需要规划三个网段：</p>
<ul>
<li>宿主机网段：Kubernetes集群节点的网段</li>
<li>Pod网段：集群内Pod的网段，相当于容器的IP</li>
<li>Service网段：集群内服务发现使用的网段，service用于集群容器通信</li>
</ul>
<p>生产环境根据申请到的IP资源进行分配即可，原则是三个网段不允许有重合IP。IP网段计算可以参考：<a href="http://tools.jb51.net/aideddesign/ip_net_calc/"  target="_blank" rel="noopener" style="color:#42b983" ;>在线IP地址计算</a>。本文虚拟机练习环境IP地址网段分配如下：</p>
<ul>
<li>宿主机网段：<code>192.168.43.1/24</code></li>
<li>Pod网段：<code>172.16.0.0/12</code></li>
<li>Service：<code>10.96.0.0/12</code></li>
</ul>
<h3 id="节点分配">节点分配<a hidden class="anchor" aria-hidden="true" href="#节点分配">#</a></h3>
<p>采用<code>3管理节点2工作节点</code>的高可用Kubernetes集群模式：</p>
<ul>
<li>k8s-master01/k8s-master02/k8s-master03 集群的Master节点</li>
<li>三个master节点同时做etcd集群</li>
<li>k8s-node01/k8s-node02 集群的Node节点</li>
<li>k8s-master-vip做高可用k8s-master01~03的VIP，不占用物理资源</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">主机节点名称</th>
<th style="text-align:center">IP</th>
<th style="text-align:center">CPU核心数</th>
<th style="text-align:center">内存大小</th>
<th style="text-align:center">磁盘大小</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">k8s-master-vip</td>
<td style="text-align:center">192.168.43.182</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
<td style="text-align:center">/</td>
</tr>
<tr>
<td style="text-align:left">k8s-master01</td>
<td style="text-align:center">192.168.43.183</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2G</td>
<td style="text-align:center">40G</td>
</tr>
<tr>
<td style="text-align:left">k8s-master02</td>
<td style="text-align:center">192.168.43.184</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2G</td>
<td style="text-align:center">40G</td>
</tr>
<tr>
<td style="text-align:left">k8s-master03</td>
<td style="text-align:center">192.168.43.185</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2G</td>
<td style="text-align:center">40G</td>
</tr>
<tr>
<td style="text-align:left">k8s-node01</td>
<td style="text-align:center">192.168.43.186</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2G</td>
<td style="text-align:center">40G</td>
</tr>
<tr>
<td style="text-align:left">k8s-node02</td>
<td style="text-align:center">192.168.43.187</td>
<td style="text-align:center">2</td>
<td style="text-align:center">2G</td>
<td style="text-align:center">40G</td>
</tr>
</tbody>
</table>
<h2 id="操作步骤">操作步骤<a hidden class="anchor" aria-hidden="true" href="#操作步骤">#</a></h2>
<p>标题后小括号注释表明操作范围：</p>
<ul>
<li>ALL 所有节点（k8s-master01/k8s-master02/k8s-master03/k8s-node01/k9s-node02）执行</li>
<li>Master 只需要在master节点（k8s-master01/k8s-master02/k8s-master03）执行</li>
<li>Node 只需要在node节点（k8s-node01/k8s-node02）执行</li>
<li>已标注的个别命令只需要在某一台机器执行，会在操作前说明</li>
<li>未标注的会在操作时说明</li>
</ul>
<p>使用<code>cat &lt;&lt; &quot;EOF&quot; &gt;&gt; file</code>或<code>cat &gt;&gt; file &lt;&lt; &quot;EOF&quot;</code>添加文件内容注意cat后面的EOF一定要加上双引号（标准输入的），否则不会保留输入时的缩进格式而且会直接解析输入时的变量，进而造成文件可读性差甚至不可用；同时注意文件的<code>&gt;</code>重写与<code>&gt;&gt;</code>追加。虽然单独转义输入时的变量也能避免变量被解析，但是不推荐，漏转义会造成不必要的麻烦。</p>
<h3 id="准备工作all">准备工作(ALL)<a hidden class="anchor" aria-hidden="true" href="#准备工作all">#</a></h3>
<p>添加主机信息、关闭防火墙、关闭swap、关闭SELinux、dnsmasq、NetworkManager</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 添加主机信息</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt;&gt; /etc/hosts
</span></span><span style="display:flex;"><span>192.168.43.182    k8s-master-vip
</span></span><span style="display:flex;"><span>192.168.43.183    k8s-master01
</span></span><span style="display:flex;"><span>192.168.43.184    k8s-master02
</span></span><span style="display:flex;"><span>192.168.43.185    k8s-master03
</span></span><span style="display:flex;"><span>192.168.43.186    k8s-node01
</span></span><span style="display:flex;"><span>192.168.43.187    k8s-node02
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 关闭防火墙、dnsmasq、NetworkManager，--now参数表示关闭服务并移除开机自启</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 这些服务是否可以关闭视情况而定，本文是虚拟机实践，没有用到这些服务</span>
</span></span><span style="display:flex;"><span>systemctl disable --now firewalld
</span></span><span style="display:flex;"><span>systemctl disable --now dnsmasq
</span></span><span style="display:flex;"><span>systemctl disable --now NetworkManager
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 关闭swap，并注释fstab文件swap所在行</span>
</span></span><span style="display:flex;"><span>swapoff -a
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#39;/swap/s/^\(.*\)$/#\1/g&#39;</span> /etc/fstab
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 关闭SELinux，并更改selinux配置文件</span>
</span></span><span style="display:flex;"><span>setenforce <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#34;s/=enforcing/=disabled/g&#34;</span> /etc/selinux/config
</span></span></code></pre></div><p>值得注意的是<code>/etc/sysconfig/selinux</code>文件是<code>/etc/selinux/config</code>文件的软连接，用<code>sed -i</code>命令修改软连接文件会破坏软连接属性，将<code>/etc/sysconfig/selinux</code>变为一个独立的文件，即使该文件被修改了，但源文件<code>/etc/selinux/config</code>配置是没变的。此外，使用vim等编辑器编辑源文件或链接文件（编辑模式不会修改文件属性）修改也可以。软链接原理可参考博客：<a href="http://www.deemoprobe.com/yunv/inode/"  target="_blank" rel="noopener" style="color:#42b983" ;>LINUX之INODE详解</a></p>
<h3 id="必要操作all">必要操作(ALL)<a hidden class="anchor" aria-hidden="true" href="#必要操作all">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 默认的yum源太慢，更新为阿里源，同时用sed命令删除文件中不需要的两个URL的行</span>
</span></span><span style="display:flex;"><span>curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo
</span></span><span style="display:flex;"><span>sed -i -e <span style="color:#e6db74">&#39;/mirrors.cloud.aliyuncs.com/d&#39;</span> -e <span style="color:#e6db74">&#39;/mirrors.aliyuncs.com/d&#39;</span> /etc/yum.repos.d/CentOS-Base.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 安装常用工具包</span>
</span></span><span style="display:flex;"><span>yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 配置阿里Kubernetes源，如果提示gpg文件有问题，可以改为gpgcheck=0，并把后三行删除（仅限测试环境使用）</span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">repo_gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 配置ntpdate，同步服务器时间</span>
</span></span><span style="display:flex;"><span>rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm
</span></span><span style="display:flex;"><span>yum install ntpdate -y
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 同步时区和时间</span>
</span></span><span style="display:flex;"><span>ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#39;Asia/Shanghai&#39;</span> &gt;/etc/timezone
</span></span><span style="display:flex;"><span>ntpdate time2.aliyun.com
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 可以加入计划任务，保证集群时钟是一致的</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /var/spool/cron/root文件也是crontab -e写入的文件</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># crontab执行日志查看可用：tail -f /var/log/cron</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt;&gt; /var/spool/cron/root
</span></span><span style="display:flex;"><span>*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 保证文件句柄不会限制集群的可持续发展，配置limits</span>
</span></span><span style="display:flex;"><span>ulimit -SHn <span style="color:#ae81ff">65500</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt;&gt; /etc/security/limits.conf
</span></span><span style="display:flex;"><span>* soft nofile <span style="color:#ae81ff">65500</span>
</span></span><span style="display:flex;"><span>* hard nofile <span style="color:#ae81ff">65500</span>
</span></span><span style="display:flex;"><span>* soft nproc <span style="color:#ae81ff">65500</span>
</span></span><span style="display:flex;"><span>* hard nproc <span style="color:#ae81ff">65500</span>
</span></span><span style="display:flex;"><span>* soft memlock unlimited
</span></span><span style="display:flex;"><span>* hard memlock unlimited
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 配置免密登录，k8s-master01到其他节点</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 生成密钥对（在k8s-master01节点配置即可）</span>
</span></span><span style="display:flex;"><span>ssh-keygen -t rsa
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 拷贝公钥到其他节点，首次需要认证一下各个节点的root密码，以后就可以免密ssh到其他节点</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i in k8s-master02 k8s-master03 k8s-node01 k8s-node02;<span style="color:#66d9ef">do</span> ssh-copy-id -i .ssh/id_rsa.pub $i;<span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 克隆二进制仓库文件（k8s-master01上操作即可）</span>
</span></span><span style="display:flex;"><span>cd root;git clone https://gitee.com/deemoprobe/k8s-ha-install.git
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cd k8s-ha-install;git branch -a
</span></span><span style="display:flex;"><span>* master
</span></span><span style="display:flex;"><span>  remotes/origin/HEAD -&gt; origin/master
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.16.x
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.17.x
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.18.x
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.19.x
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.20.x
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.20.x-csi-hostpath
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.21.x
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.22.x
</span></span><span style="display:flex;"><span>  remotes/origin/manual-installation-v1.23.x
</span></span><span style="display:flex;"><span>  remotes/origin/master
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 可以切换到需要版本的分支中获取配置文件</span>
</span></span><span style="display:flex;"><span>git checkout manual-installation-v1.22.x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 所有节点系统升级</span>
</span></span><span style="display:flex;"><span>yum update --exclude<span style="color:#f92672">=</span>kernel* -y
</span></span></code></pre></div><p>升级内核，4.17以下的内核cgroup存在内存泄漏的BUG，具体分析过程浏览器搜<code>Kubernetes集群为什么要升级内核</code>会有很多文章讲解</p>
<p>内核备用下载（建议下载到本地后上传到服务器，尽量不用<code>wget</code>）：</p>
<ul>
<li><a href="https://deemoprobe.oss-cn-shanghai.aliyuncs.com/repo/kernel-ml-devel-4.19.12-1.el7.elrepo.x86_64.rpm?versionId=CAEQNBiBgMDJiNbj.hciIDUyMDZlYjU5YzIwMzQ0MmNhNzBmNjBiMDY3Yjc0Y2Jl"  target="_blank" rel="noopener" style="color:#42b983" ;>kernel-ml-devel-4.19.12-1.el7.elrepo.x86_64.rpm</a></li>
<li><a href="https://deemoprobe.oss-cn-shanghai.aliyuncs.com/repo/kernel-ml-4.19.12-1.el7.elrepo.x86_64.rpm?versionId=CAEQNBiBgMDNiNbj.hciIGQ0M2RmZDAwNDhlNjQyNjE5MTE4MDk1OGU4OThiNWY4"  target="_blank" rel="noopener" style="color:#42b983" ;>kernel-ml-4.19.12-1.el7.elrepo.x86_64.rpm</a></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 下载4.19版本内核，如果无法下载，可以用上面提供的备用下载</span>
</span></span><span style="display:flex;"><span>cd /root
</span></span><span style="display:flex;"><span>wget http://193.49.22.109/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-devel-4.19.12-1.el7.elrepo.x86_64.rpm
</span></span><span style="display:flex;"><span>wget http://193.49.22.109/elrepo/kernel/el7/x86_64/RPMS/kernel-ml-4.19.12-1.el7.elrepo.x86_64.rpm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 可以在k8s-master01节点下载后，免密传到其他节点</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i in k8s-master02 k8s-master03 k8s-node01 k8s-node02;<span style="color:#66d9ef">do</span> scp kernel-ml-* $i:/root;<span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 所有节点安装内核</span>
</span></span><span style="display:flex;"><span>cd /root <span style="color:#f92672">&amp;&amp;</span> yum localinstall -y kernel-ml*
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 所有节点更改内核启动顺序</span>
</span></span><span style="display:flex;"><span>grub2-set-default  <span style="color:#ae81ff">0</span> <span style="color:#f92672">&amp;&amp;</span> grub2-mkconfig -o /etc/grub2.cfg
</span></span><span style="display:flex;"><span>grubby --args<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;user_namespace.enable=1&#34;</span> --update-kernel<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span><span style="color:#66d9ef">$(</span>grubby --default-kernel<span style="color:#66d9ef">)</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 查看默认内核，并重启节点</span>
</span></span><span style="display:flex;"><span>grubby --default-kernel
</span></span><span style="display:flex;"><span>reboot
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 确认内核版本</span>
</span></span><span style="display:flex;"><span>uname -a
</span></span><span style="display:flex;"><span><span style="color:#75715e"># （可选）删除老版本的内核，避免以后被升级取代默认的开机4.19内核</span>
</span></span><span style="display:flex;"><span>rpm -qa | grep kernel
</span></span><span style="display:flex;"><span>yum remove -y kernel-3*
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 升级系统软件包（如果跳过内核升级加参数 --exclude=kernel*）</span>
</span></span><span style="display:flex;"><span>yum update -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 安装IPVS相关工具，由于IPVS在资源消耗和性能上均已明显优于iptables，所以推荐开启</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 具体原因可参考官网介绍 https://kubernetes.io/zh/blog/2018/07/09/ipvs-based-in-cluster-load-balancing-deep-dive/</span>
</span></span><span style="display:flex;"><span>yum install ipvsadm ipset sysstat conntrack libseccomp -y
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载模块，最后一条4.18及以下内核使用nf_conntrack_ipv4，4.19已改为nf_conntrack</span>
</span></span><span style="display:flex;"><span>modprobe -- ip_vs
</span></span><span style="display:flex;"><span>modprobe -- ip_vs_rr
</span></span><span style="display:flex;"><span>modprobe -- ip_vs_wrr
</span></span><span style="display:flex;"><span>modprobe -- ip_vs_sh
</span></span><span style="display:flex;"><span>modprobe -- nf_conntrack
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 编写参数文件</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; /etc/modules-load.d/ipvs.conf 
</span></span><span style="display:flex;"><span>ip_vs
</span></span><span style="display:flex;"><span>ip_vs_lc
</span></span><span style="display:flex;"><span>ip_vs_wlc
</span></span><span style="display:flex;"><span>ip_vs_rr
</span></span><span style="display:flex;"><span>ip_vs_wrr
</span></span><span style="display:flex;"><span>ip_vs_lblc
</span></span><span style="display:flex;"><span>ip_vs_lblcr
</span></span><span style="display:flex;"><span>ip_vs_dh
</span></span><span style="display:flex;"><span>ip_vs_sh
</span></span><span style="display:flex;"><span>ip_vs_fo
</span></span><span style="display:flex;"><span>ip_vs_nq
</span></span><span style="display:flex;"><span>ip_vs_sed
</span></span><span style="display:flex;"><span>ip_vs_ftp
</span></span><span style="display:flex;"><span>ip_vs_sh
</span></span><span style="display:flex;"><span>nf_conntrack
</span></span><span style="display:flex;"><span>ip_tables
</span></span><span style="display:flex;"><span>ip_set
</span></span><span style="display:flex;"><span>xt_set
</span></span><span style="display:flex;"><span>ipt_set
</span></span><span style="display:flex;"><span>ipt_rpfilter
</span></span><span style="display:flex;"><span>ipt_REJECT
</span></span><span style="display:flex;"><span>ipip
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># systemd-modules-load加入开机自启</span>
</span></span><span style="display:flex;"><span>systemctl enable --now systemd-modules-load
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 自定义内核参数优化配置文件</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; /etc/sysctl.d/kubernetes.conf
</span></span><span style="display:flex;"><span>net.ipv4.ip_forward <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net.bridge.bridge-nf-call-iptables <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net.bridge.bridge-nf-call-ip6tables <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>fs.may_detach_mounts <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net.ipv4.conf.all.route_localnet <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>vm.overcommit_memory<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>vm.panic_on_oom<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>fs.inotify.max_user_watches<span style="color:#f92672">=</span><span style="color:#ae81ff">89100</span>
</span></span><span style="display:flex;"><span>fs.file-max<span style="color:#f92672">=</span><span style="color:#ae81ff">52706963</span>
</span></span><span style="display:flex;"><span>fs.nr_open<span style="color:#f92672">=</span><span style="color:#ae81ff">52706963</span>
</span></span><span style="display:flex;"><span>net.netfilter.nf_conntrack_max<span style="color:#f92672">=</span><span style="color:#ae81ff">2310720</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_keepalive_time <span style="color:#f92672">=</span> <span style="color:#ae81ff">600</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_keepalive_probes <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_keepalive_intvl <span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_max_tw_buckets <span style="color:#f92672">=</span> <span style="color:#ae81ff">36000</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_tw_reuse <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_max_orphans <span style="color:#f92672">=</span> <span style="color:#ae81ff">327680</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_orphan_retries <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_syncookies <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_max_syn_backlog <span style="color:#f92672">=</span> <span style="color:#ae81ff">16384</span>
</span></span><span style="display:flex;"><span>net.ipv4.ip_conntrack_max <span style="color:#f92672">=</span> <span style="color:#ae81ff">65536</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_max_syn_backlog <span style="color:#f92672">=</span> <span style="color:#ae81ff">16384</span>
</span></span><span style="display:flex;"><span>net.ipv4.tcp_timestamps <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>net.core.somaxconn <span style="color:#f92672">=</span> <span style="color:#ae81ff">16384</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载</span>
</span></span><span style="display:flex;"><span>sysctl --system
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 重启查看IPVS模块是否依旧加载</span>
</span></span><span style="display:flex;"><span>reboot
</span></span><span style="display:flex;"><span>lsmod | grep -e ip_vs -e nf_conntrack
</span></span></code></pre></div><ul>
<li>保证每台服务器中IPVS加载成功，以k8s-master01为例，如图：</li>
</ul>
<p><img loading="lazy" src="https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20220305153926.png" alt="20220305153926"  />
</p>
<h3 id="部署dockerall">部署Docker(ALL)<a hidden class="anchor" aria-hidden="true" href="#部署dockerall">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 卸载已存在docker，新机器的话这步可以忽略</span>
</span></span><span style="display:flex;"><span>yum remove -y docker <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>              docker-client <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>              docker-client-latest <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>              docker-common <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>              docker-latest <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>              docker-latest-logrotate <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>              docker-logrotate <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>              docker-engine
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>yum remove -y docker-ce docker-ce-cli containerd.io
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 配置阿里docker源</span>
</span></span><span style="display:flex;"><span>yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 安装最新版本docker</span>
</span></span><span style="display:flex;"><span>yum install docker-ce docker-ce-cli containerd.io -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># （可选）如果想要安装指定版本docker，先查询一下。安装指定版本，例如20.10.9-3.el7</span>
</span></span><span style="display:flex;"><span>yum list docker-ce docker-ce-cli --showduplicates | grep <span style="color:#e6db74">&#34;^doc&#34;</span> | sort -r
</span></span><span style="display:flex;"><span>yum install docker-ce-20.10.9-3.el7 docker-ce-cli-20.10.9-3.el7 containerd.io -y
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加入开机启动并启动</span>
</span></span><span style="display:flex;"><span>systemctl enable docker
</span></span><span style="display:flex;"><span>systemctl start docker
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 测试运行hello-world镜像并查看docker版本信息</span>
</span></span><span style="display:flex;"><span>docker run hello-world
</span></span><span style="display:flex;"><span>docker version
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 配置阿里docker镜像加速器，阿里云(登录账号--&gt;点击管理控制台--&gt;搜索容器镜像服务--&gt;镜像工具--&gt;镜像加速器--&gt;复制加速器地址)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># docker文件驱动改成 systemd</span>
</span></span><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF &gt; /etc/docker/daemon.json
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;registry-mirrors&#34;: [&#34;https://ynirk4k5.mirror.aliyuncs.com&#34;]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 重启docker</span>
</span></span><span style="display:flex;"><span>systemctl restart docker
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如果启动失败,强制加载再启动试试</span>
</span></span><span style="display:flex;"><span>systemctl reset-failed docker
</span></span><span style="display:flex;"><span>systemctl restart docker
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 查看docker配置信息</span>
</span></span><span style="display:flex;"><span>docker info
</span></span><span style="display:flex;"><span>docker info | grep Driver
</span></span></code></pre></div><h3 id="安装kubernetesall">安装kubernetes(ALL)<a hidden class="anchor" aria-hidden="true" href="#安装kubernetesall">#</a></h3>
<p>一般kubectl在master节点安装即可,node节点装不装均可</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 查看可以安装的版本号</span>
</span></span><span style="display:flex;"><span>yum list kubeadm --showduplicates | sort -r
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 不指定版本的话默认安装最新版本安装</span>
</span></span><span style="display:flex;"><span>yum install -y kubelet kubeadm kubectl
</span></span><span style="display:flex;"><span><span style="color:#75715e"># （可选）指定版本进行安装，如1.23.0</span>
</span></span><span style="display:flex;"><span>yum install -y kubelet-1.23.0 kubeadm-1.23.0 kubectl-1.23.0
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 配置pause镜像仓库，默认的gcr.io国内无法访问，可以使用阿里仓库</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; /etc/sysconfig/kubelet
</span></span><span style="display:flex;"><span>KUBELET_EXTRA_ARGS<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5&#34;</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加入开机启动并启动，此处启动失败不必排查，待初始化完成kubelet会自动恢复正常</span>
</span></span><span style="display:flex;"><span>systemctl enable --now kubelet
</span></span></code></pre></div><h3 id="高可用组件安装master">高可用组件安装(Master)<a hidden class="anchor" aria-hidden="true" href="#高可用组件安装master">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 所有master节点安装Keepalived和haproxy</span>
</span></span><span style="display:flex;"><span>yum install keepalived haproxy -y
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 为所有master节点添加haproxy配置，配置都一样，检查最后三行主机名和IP地址对应上就行</span>
</span></span><span style="display:flex;"><span>mkdir /etc/haproxy
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; /etc/haproxy/haproxy.cfg
</span></span><span style="display:flex;"><span>global
</span></span><span style="display:flex;"><span>  maxconn  <span style="color:#ae81ff">2000</span>
</span></span><span style="display:flex;"><span>  ulimit-n  <span style="color:#ae81ff">16384</span>
</span></span><span style="display:flex;"><span>  log  127.0.0.1 local0 err
</span></span><span style="display:flex;"><span>  stats timeout 30s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>defaults
</span></span><span style="display:flex;"><span>  log global
</span></span><span style="display:flex;"><span>  mode  http
</span></span><span style="display:flex;"><span>  option  httplog
</span></span><span style="display:flex;"><span>  timeout connect <span style="color:#ae81ff">5000</span>
</span></span><span style="display:flex;"><span>  timeout client  <span style="color:#ae81ff">50000</span>
</span></span><span style="display:flex;"><span>  timeout server  <span style="color:#ae81ff">50000</span>
</span></span><span style="display:flex;"><span>  timeout http-request 15s
</span></span><span style="display:flex;"><span>  timeout http-keep-alive 15s
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>frontend monitor-in
</span></span><span style="display:flex;"><span>  bind *:33305
</span></span><span style="display:flex;"><span>  mode http
</span></span><span style="display:flex;"><span>  option httplog
</span></span><span style="display:flex;"><span>  monitor-uri /monitor
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>frontend k8s-master
</span></span><span style="display:flex;"><span>  bind 0.0.0.0:16443
</span></span><span style="display:flex;"><span>  bind 127.0.0.1:16443
</span></span><span style="display:flex;"><span>  mode tcp
</span></span><span style="display:flex;"><span>  option tcplog
</span></span><span style="display:flex;"><span>  tcp-request inspect-delay 5s
</span></span><span style="display:flex;"><span>  default_backend k8s-master
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>backend k8s-master
</span></span><span style="display:flex;"><span>  mode tcp
</span></span><span style="display:flex;"><span>  option tcplog
</span></span><span style="display:flex;"><span>  option tcp-check
</span></span><span style="display:flex;"><span>  balance roundrobin
</span></span><span style="display:flex;"><span>  default-server inter 10s downinter 5s rise <span style="color:#ae81ff">2</span> fall <span style="color:#ae81ff">2</span> slowstart 60s maxconn <span style="color:#ae81ff">250</span> maxqueue <span style="color:#ae81ff">256</span> weight <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>  server k8s-master01  192.168.43.183:6443  check
</span></span><span style="display:flex;"><span>  server k8s-master02  192.168.43.184:6443  check
</span></span><span style="display:flex;"><span>  server k8s-master03  192.168.43.185:6443  check
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># keepalived配置不一样，注意区分网卡名、IP地址和虚拟IP地址</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 检查服务器网卡名</span>
</span></span><span style="display:flex;"><span>ip a 或 ifconfig
</span></span><span style="display:flex;"><span><span style="color:#75715e"># k8s-master01 Keepalived配置</span>
</span></span><span style="display:flex;"><span>mkdir /etc/keepalived
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; /etc/keepalived/keepalived.conf
</span></span><span style="display:flex;"><span>! Configuration File <span style="color:#66d9ef">for</span> keepalived
</span></span><span style="display:flex;"><span>global_defs <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    router_id LVS_DEVEL
</span></span><span style="display:flex;"><span>    script_user root
</span></span><span style="display:flex;"><span>    enable_script_security
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>vrrp_script chk_apiserver <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    script <span style="color:#e6db74">&#34;/etc/keepalived/check_apiserver.sh&#34;</span>
</span></span><span style="display:flex;"><span>    interval <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>    weight -5
</span></span><span style="display:flex;"><span>    fall <span style="color:#ae81ff">2</span>  
</span></span><span style="display:flex;"><span>    rise <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>vrrp_instance VI_1 <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    state MASTER
</span></span><span style="display:flex;"><span>    interface ens33
</span></span><span style="display:flex;"><span>    mcast_src_ip 192.168.43.183
</span></span><span style="display:flex;"><span>    virtual_router_id <span style="color:#ae81ff">51</span>
</span></span><span style="display:flex;"><span>    priority <span style="color:#ae81ff">101</span>
</span></span><span style="display:flex;"><span>    advert_int <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    authentication <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        auth_type PASS
</span></span><span style="display:flex;"><span>        auth_pass K8SHA_KA_AUTH
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    virtual_ipaddress <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        192.168.43.182
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    track_script <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>       chk_apiserver
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># k8s-master02 Keepalived配置</span>
</span></span><span style="display:flex;"><span>mkdir /etc/keepalived
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; /etc/keepalived/keepalived.conf
</span></span><span style="display:flex;"><span>! Configuration File <span style="color:#66d9ef">for</span> keepalived
</span></span><span style="display:flex;"><span>global_defs <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    router_id LVS_DEVEL
</span></span><span style="display:flex;"><span>    script_user root
</span></span><span style="display:flex;"><span>    enable_script_security
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>vrrp_script chk_apiserver <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    script <span style="color:#e6db74">&#34;/etc/keepalived/check_apiserver.sh&#34;</span>
</span></span><span style="display:flex;"><span>    interval <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>    weight -5
</span></span><span style="display:flex;"><span>    fall <span style="color:#ae81ff">2</span>  
</span></span><span style="display:flex;"><span>    rise <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>vrrp_instance VI_1 <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    state BACKUP
</span></span><span style="display:flex;"><span>    interface ens33
</span></span><span style="display:flex;"><span>    mcast_src_ip 192.168.43.184
</span></span><span style="display:flex;"><span>    virtual_router_id <span style="color:#ae81ff">51</span>
</span></span><span style="display:flex;"><span>    priority <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>    advert_int <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    authentication <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        auth_type PASS
</span></span><span style="display:flex;"><span>        auth_pass K8SHA_KA_AUTH
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    virtual_ipaddress <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        192.168.43.182
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    track_script <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>       chk_apiserver
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># k8s-master03 Keepalived配置</span>
</span></span><span style="display:flex;"><span>mkdir /etc/keepalived
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; /etc/keepalived/keepalived.conf
</span></span><span style="display:flex;"><span>! Configuration File <span style="color:#66d9ef">for</span> keepalived
</span></span><span style="display:flex;"><span>global_defs <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    router_id LVS_DEVEL
</span></span><span style="display:flex;"><span>    script_user root
</span></span><span style="display:flex;"><span>    enable_script_security
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>vrrp_script chk_apiserver <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    script <span style="color:#e6db74">&#34;/etc/keepalived/check_apiserver.sh&#34;</span>
</span></span><span style="display:flex;"><span>    interval <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>    weight -5
</span></span><span style="display:flex;"><span>    fall <span style="color:#ae81ff">2</span>  
</span></span><span style="display:flex;"><span>    rise <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>vrrp_instance VI_1 <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    state BACKUP
</span></span><span style="display:flex;"><span>    interface ens33
</span></span><span style="display:flex;"><span>    mcast_src_ip 192.168.43.185
</span></span><span style="display:flex;"><span>    virtual_router_id <span style="color:#ae81ff">51</span>
</span></span><span style="display:flex;"><span>    priority <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>    advert_int <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    authentication <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        auth_type PASS
</span></span><span style="display:flex;"><span>        auth_pass K8SHA_KA_AUTH
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    virtual_ipaddress <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        192.168.43.182
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>    track_script <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>       chk_apiserver
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 所有master节点配置Keepalived健康检查脚本</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; /etc/keepalived/check_apiserver.sh 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash</span>
</span></span><span style="display:flex;"><span>err<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k in <span style="color:#66d9ef">$(</span>seq <span style="color:#ae81ff">1</span> 3<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>    check_code<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>pgrep haproxy<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#f92672">[[</span> $check_code <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;&#34;</span> <span style="color:#f92672">]]</span>; <span style="color:#66d9ef">then</span>
</span></span><span style="display:flex;"><span>        err<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>expr $err + 1<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>        sleep <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>
</span></span><span style="display:flex;"><span>        err<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        break
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">fi</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> <span style="color:#f92672">[[</span> $err !<span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;0&#34;</span> <span style="color:#f92672">]]</span>; <span style="color:#66d9ef">then</span>
</span></span><span style="display:flex;"><span>    echo <span style="color:#e6db74">&#34;systemctl stop keepalived&#34;</span>
</span></span><span style="display:flex;"><span>    /usr/bin/systemctl stop keepalived
</span></span><span style="display:flex;"><span>    exit <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">else</span>
</span></span><span style="display:flex;"><span>    exit <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fi</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 赋予可执行权限</span>
</span></span><span style="display:flex;"><span>chmod +x /etc/keepalived/check_apiserver.sh
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 启动haproxy和Keepalived并加入开机启动</span>
</span></span><span style="display:flex;"><span>systemctl start haproxy
</span></span><span style="display:flex;"><span>systemctl start keepalived
</span></span><span style="display:flex;"><span>systemctl enable haproxy
</span></span><span style="display:flex;"><span>systemctl enable keepalived
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 测试一波</span>
</span></span><span style="display:flex;"><span>telnet k8s-master-vip <span style="color:#ae81ff">16443</span>
</span></span><span style="display:flex;"><span>ping k8s-master-vip
</span></span></code></pre></div><h3 id="部署k8s-masterk8s-master01">部署k8s-master(k8s-master01)<a hidden class="anchor" aria-hidden="true" href="#部署k8s-masterk8s-master01">#</a></h3>
<p>在k8s-master01节点上执行，个别步骤在所有master节点执行，已另行说明，没说明的均是在k8s-master01执行。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 创建初始化文件，注意版本号和IP对应上</span>
</span></span><span style="display:flex;"><span>cat &lt;&lt; <span style="color:#e6db74">&#34;EOF&#34;</span> &gt; kubeadm-config.yaml
</span></span><span style="display:flex;"><span>apiVersion: kubeadm.k8s.io/v1beta2
</span></span><span style="display:flex;"><span>bootstrapTokens:
</span></span><span style="display:flex;"><span>- groups:
</span></span><span style="display:flex;"><span>  - system:bootstrappers:kubeadm:default-node-token
</span></span><span style="display:flex;"><span>  token: 7t2weq.bjbawausm0jaxury
</span></span><span style="display:flex;"><span>  ttl: 24h0m0s
</span></span><span style="display:flex;"><span>  usages:
</span></span><span style="display:flex;"><span>  - signing
</span></span><span style="display:flex;"><span>  - authentication
</span></span><span style="display:flex;"><span>kind: InitConfiguration
</span></span><span style="display:flex;"><span>localAPIEndpoint:
</span></span><span style="display:flex;"><span>  advertiseAddress: 192.168.43.183 <span style="color:#75715e"># API通知地址，设置为初始化IP即可</span>
</span></span><span style="display:flex;"><span>  bindPort: <span style="color:#ae81ff">6443</span>
</span></span><span style="display:flex;"><span>nodeRegistration:
</span></span><span style="display:flex;"><span>  criSocket: /var/run/dockershim.sock <span style="color:#75715e"># docker作为Container Runtime</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># criSocket: /run/containerd/containerd.sock # containerd作为Container Runtime</span>
</span></span><span style="display:flex;"><span>  name: k8s-master01 <span style="color:#75715e"># 初始化节点名</span>
</span></span><span style="display:flex;"><span>  taints:
</span></span><span style="display:flex;"><span>  - effect: NoSchedule
</span></span><span style="display:flex;"><span>    key: node-role.kubernetes.io/master
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span>apiServer:
</span></span><span style="display:flex;"><span>  certSANs:
</span></span><span style="display:flex;"><span>  - 192.168.43.182
</span></span><span style="display:flex;"><span>  timeoutForControlPlane: 4m0s <span style="color:#75715e"># 初始化超时时间</span>
</span></span><span style="display:flex;"><span>apiVersion: kubeadm.k8s.io/v1beta2
</span></span><span style="display:flex;"><span>certificatesDir: /etc/kubernetes/pki
</span></span><span style="display:flex;"><span>clusterName: kubernetes
</span></span><span style="display:flex;"><span>controlPlaneEndpoint: 192.168.43.182:16443 <span style="color:#75715e"># 如果不是高可用集群，则为6443</span>
</span></span><span style="display:flex;"><span>controllerManager: <span style="color:#f92672">{}</span>
</span></span><span style="display:flex;"><span>dns:
</span></span><span style="display:flex;"><span>  type: CoreDNS
</span></span><span style="display:flex;"><span>etcd:
</span></span><span style="display:flex;"><span>  local:
</span></span><span style="display:flex;"><span>    dataDir: /var/lib/etcd
</span></span><span style="display:flex;"><span>imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers <span style="color:#75715e"># 国内地址</span>
</span></span><span style="display:flex;"><span>kind: ClusterConfiguration
</span></span><span style="display:flex;"><span>kubernetesVersion: v1.23.0 <span style="color:#75715e"># 需与kubeadm version版本号保持一致</span>
</span></span><span style="display:flex;"><span>networking:
</span></span><span style="display:flex;"><span>  dnsDomain: cluster.local
</span></span><span style="display:flex;"><span>  podSubnet: 172.16.0.0/12 <span style="color:#75715e"># 不可与其他IP段冲突</span>
</span></span><span style="display:flex;"><span>  serviceSubnet: 10.96.0.0/12 <span style="color:#75715e"># 不可与其他IP段冲突</span>
</span></span><span style="display:flex;"><span>scheduler: <span style="color:#f92672">{}</span>
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 更新初始化文件</span>
</span></span><span style="display:flex;"><span>kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 将new.yaml复制到其他master节点上</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i in k8s-master02 k8s-master03;<span style="color:#66d9ef">do</span> scp new.yaml $i:/root/;<span style="color:#66d9ef">done</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 镜像预下载，节省集群初始化的时间（这一步在所有master节点上执行）</span>
</span></span><span style="display:flex;"><span>kubeadm config images pull --config /root/new.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 执行结果如下</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.23.0
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.23.0
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.23.0
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.23.0
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.1-0
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>config/images<span style="color:#f92672">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.6
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># master01初始化，初始化完成后，加入其他节点即可</span>
</span></span><span style="display:flex;"><span>kubeadm init --config /root/new.yaml  --upload-certs
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 初始化如果失败，可用下面命令清除初始化信息，然后再次尝试初始化</span>
</span></span><span style="display:flex;"><span>kubeadm reset -f ; ipvsadm --clear  ; rm -rf ~/.kube
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 初始化成功类似于下面输出，保存好这些信息</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Your Kubernetes control-plane has initialized successfully!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>To start using your cluster, you need to run the following as a regular user:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>  sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Alternatively, <span style="color:#66d9ef">if</span> you are the root user, you can run:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  export KUBECONFIG<span style="color:#f92672">=</span>/etc/kubernetes/admin.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>You should now deploy a pod network to the cluster.
</span></span><span style="display:flex;"><span>Run <span style="color:#e6db74">&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
</span></span><span style="display:flex;"><span>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>You can now join any number of the control-plane node running the following command on each as root:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --control-plane --certificate-key 9a2e86718fceba001c96e503e9df47db3a645d4917bf783decaea9c5d0a726ed
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
</span></span><span style="display:flex;"><span>As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;kubeadm init phase upload-certs --upload-certs&#34;</span> to reload certs afterward.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Then you can join any number of worker nodes by running the following on each as root:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 按照提示，如果你是普通用户在操作，执行一下下面几条</span>
</span></span><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如果是root用户在操作初始化，执行下面一条即可</span>
</span></span><span style="display:flex;"><span>export KUBECONFIG<span style="color:#f92672">=</span>/etc/kubernetes/admin.conf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 查看docker镜像,可以看到kube..和etcd等镜像</span>
</span></span><span style="display:flex;"><span>docker images
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Token过期后生成新的token（没提示过期下面两步就不用管了）</span>
</span></span><span style="display:flex;"><span>kubeadm token create --print-join-command
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Master需要生成--certificate-key</span>
</span></span><span style="display:flex;"><span>kubeadm init phase upload-certs  --upload-certs
</span></span></code></pre></div><h3 id="其他节点加入集群">其他节点加入集群<a hidden class="anchor" aria-hidden="true" href="#其他节点加入集群">#</a></h3>
<p>其他master节点加入k8s-master01</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 根据kubeadm init提示的token</span>
</span></span><span style="display:flex;"><span>kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --control-plane --certificate-key 9a2e86718fceba001c96e503e9df47db3a645d4917bf783decaea9c5d0a726ed
</span></span></code></pre></div><p>node节点加入k8s-master01</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 根据kubeadm init提示的token</span>
</span></span><span style="display:flex;"><span>kubeadm join 192.168.43.182:16443 --token 7t2weq.bjbawausm0jaxury <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        --discovery-token-ca-cert-hash sha256:5257d44118ab035adc5af89dd7d5a24ca4c31c33e1918b3453ea9aa32597121b
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># master01上查看加入后的节点信息，因为还未配置CNI插件，所以node之间通信还未打通</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 ~<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl get no</span>
</span></span><span style="display:flex;"><span>NAME           STATUS     ROLES                  AGE     VERSION
</span></span><span style="display:flex;"><span>k8s-master01   NotReady   control-plane,master   19m     v1.23.0
</span></span><span style="display:flex;"><span>k8s-master02   NotReady   control-plane,master   3m39s   v1.23.0
</span></span><span style="display:flex;"><span>k8s-master03   NotReady   control-plane,master   3m35s   v1.23.0
</span></span><span style="display:flex;"><span>k8s-node01     NotReady   &lt;none&gt;                 2m21s   v1.23.0
</span></span><span style="display:flex;"><span>k8s-node02     NotReady   &lt;none&gt;                 2m21s   v1.23.0
</span></span></code></pre></div><h3 id="配置calico网络">配置calico网络<a hidden class="anchor" aria-hidden="true" href="#配置calico网络">#</a></h3>
<p>在k8s-master01节点上执行</p>
<p>网络方案也可以选择其他(例如：flannel等)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 先把所需的配置文件从GitHub拉下来</span>
</span></span><span style="display:flex;"><span>git clone https://github.com/deemoprobe/k8s-ha-install.git
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 切换到1.23分支并进入calico文件夹</span>
</span></span><span style="display:flex;"><span>cd /root/k8s-ha-install <span style="color:#f92672">&amp;&amp;</span> git checkout manual-installation-v1.23.x <span style="color:#f92672">&amp;&amp;</span> cd calico/
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 替换一下POD网段</span>
</span></span><span style="display:flex;"><span>POD_SUBNET<span style="color:#f92672">=</span><span style="color:#e6db74">`</span>cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr<span style="color:#f92672">=</span> | awk -F<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;{print $NF}&#39;</span><span style="color:#e6db74">`</span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#e6db74">&#34;s#POD_CIDR#</span><span style="color:#e6db74">${</span>POD_SUBNET<span style="color:#e6db74">}</span><span style="color:#e6db74">#g&#34;</span> calico.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 应用calico插件</span>
</span></span><span style="display:flex;"><span>kubectl apply -f calico.yaml
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 集群节点均已处于Ready状态</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl get no</span>
</span></span><span style="display:flex;"><span>NAME           STATUS   ROLES                  AGE   VERSION
</span></span><span style="display:flex;"><span>k8s-master01   Ready    control-plane,master   29m   v1.23.0
</span></span><span style="display:flex;"><span>k8s-master02   Ready    control-plane,master   13m   v1.23.0
</span></span><span style="display:flex;"><span>k8s-master03   Ready    control-plane,master   13m   v1.23.0
</span></span><span style="display:flex;"><span>k8s-node01     Ready    &lt;none&gt;                 11m   v1.23.0
</span></span><span style="display:flex;"><span>k8s-node02     Ready    &lt;none&gt;                 11m   v1.23.0
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 查看calico Pod是否都正常</span>
</span></span><span style="display:flex;"><span>kubectl get pod -A
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如果不正常，可以排查一下，一般是镜像拉取问题，多等待几分钟即可，也可以根据报错简单处理一下</span>
</span></span><span style="display:flex;"><span>kubectl describe pod XXX -n kube-system
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 比如我这里有个pod处于pending状态，查看一下原因</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl get pod -A</span>
</span></span><span style="display:flex;"><span>NAMESPACE     NAME                                       READY   STATUS    RESTARTS      AGE
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>kube-system   calico-typha-8445487f56-hx8w9              1/1     Running   <span style="color:#ae81ff">0</span>             11m
</span></span><span style="display:flex;"><span>kube-system   calico-typha-8445487f56-mh6tp              0/1     Pending   <span style="color:#ae81ff">0</span>             11m
</span></span><span style="display:flex;"><span>kube-system   calico-typha-8445487f56-pxthb              1/1     Running   <span style="color:#ae81ff">0</span>             11m
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 可以看到提示说2个node节点无法提供足量的pod端口分配需求，而且提示master节点设置了污点</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl describe pod calico-typha-8445487f56-mh6tp -n kube-system</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Events:
</span></span><span style="display:flex;"><span>  Type     Reason            Age                    From               Message
</span></span><span style="display:flex;"><span>  ----     ------            ----                   ----               -------
</span></span><span style="display:flex;"><span>  Warning  FailedScheduling  11m                    default-scheduler  0/5 nodes are available: <span style="color:#ae81ff">2</span> node<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> had taint <span style="color:#f92672">{</span>node.kubernetes.io/not-ready: <span style="color:#f92672">}</span>, that the pod didn<span style="color:#e6db74">&#39;t tolerate, 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn&#39;</span>t tolerate.
</span></span><span style="display:flex;"><span>  Warning  FailedScheduling  10m                    default-scheduler  0/5 nodes are available: <span style="color:#ae81ff">1</span> node<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> didn<span style="color:#e6db74">&#39;t have free ports for the requested pod ports, 1 node(s) had taint {node.kubernetes.io/not-ready: }, that the pod didn&#39;</span>t tolerate, <span style="color:#ae81ff">3</span> node<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> had taint <span style="color:#f92672">{</span>node-role.kubernetes.io/master: <span style="color:#f92672">}</span>, that the pod didn<span style="color:#e6db74">&#39;t tolerate.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  Warning  FailedScheduling  10m                    default-scheduler  0/5 nodes are available: 2 node(s) didn&#39;</span>t have free ports <span style="color:#66d9ef">for</span> the requested pod ports, <span style="color:#ae81ff">3</span> node<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> had taint <span style="color:#f92672">{</span>node-role.kubernetes.io/master: <span style="color:#f92672">}</span>, that the pod didn<span style="color:#e6db74">&#39;t tolerate.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  Warning  FailedScheduling  8m24s (x1 over 9m24s)  default-scheduler  0/5 nodes are available: 2 node(s) didn&#39;</span>t have free ports <span style="color:#66d9ef">for</span> the requested pod ports, <span style="color:#ae81ff">3</span> node<span style="color:#f92672">(</span>s<span style="color:#f92672">)</span> had taint <span style="color:#f92672">{</span>node-role.kubernetes.io/master: <span style="color:#f92672">}</span>, that the pod didn<span style="color:#e6db74">&#39;t tolerate.&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 确认一下，可以看到三个master节点打上了不可调度pod的污点</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># for i in k8s-master01 k8s-master02 k8s-master03;do kubectl describe node $i | grep -i taint;done</span>
</span></span><span style="display:flex;"><span>Taints:             node-role.kubernetes.io/master:NoSchedule
</span></span><span style="display:flex;"><span>Taints:             node-role.kubernetes.io/master:NoSchedule
</span></span><span style="display:flex;"><span>Taints:             node-role.kubernetes.io/master:NoSchedule
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 由于是练习环境，我就把不可调度的污点取消了，如果是生产环境，建议扩容node工作节点来实现足量的端口分配</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># for i in k8s-master01 k8s-master02 k8s-master03;do kubectl taint node $i node-role.kubernetes.io/master:NoSchedule-;done</span>
</span></span><span style="display:flex;"><span>node/k8s-master01 untainted
</span></span><span style="display:flex;"><span>node/k8s-master02 untainted
</span></span><span style="display:flex;"><span>node/k8s-master03 untainted
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 污点成功取消</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># for i in k8s-master01 k8s-master02 k8s-master03;do kubectl describe node $i | grep -i taint;done</span>
</span></span><span style="display:flex;"><span>Taints:             &lt;none&gt;
</span></span><span style="display:flex;"><span>Taints:             &lt;none&gt;
</span></span><span style="display:flex;"><span>Taints:             &lt;none&gt;
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 再查看刚才处于pending的pod发现已经处于running状态了</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl get po -A | grep calico-typha-8445487f56-mh6tp</span>
</span></span><span style="display:flex;"><span>kube-system   calico-typha-8445487f56-mh6tp              1/1     Running   <span style="color:#ae81ff">0</span>             23m
</span></span></code></pre></div><h2 id="部署metrics">部署Metrics<a hidden class="anchor" aria-hidden="true" href="#部署metrics">#</a></h2>
<p>在新版的Kubernetes中系统资源的采集均使用Metrics-server，可以通过Metrics采集节点和Pod的内存、磁盘、CPU和网络的使用率。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 将Master01节点的front-proxy-ca.crt复制到所有Node节点</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># for i in k8s-node01 k8s-node02;do scp /etc/kubernetes/pki/front-proxy-ca.crt $i:/etc/kubernetes/pki/front-proxy-ca.crt;done</span>
</span></span><span style="display:flex;"><span>front-proxy-ca.crt                                                                                                   100% <span style="color:#ae81ff">1115</span>   593.4KB/s   00:00    
</span></span><span style="display:flex;"><span>front-proxy-ca.crt                                                                                                   100% <span style="color:#ae81ff">1115</span>     1.4MB/s   00:00  
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 安装metrics server</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># cd /root/k8s-ha-install/kubeadm-metrics-server</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 kubeadm-metrics-server<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl apply -f comp.yaml </span>
</span></span><span style="display:flex;"><span>serviceaccount/metrics-server created
</span></span><span style="display:flex;"><span>clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
</span></span><span style="display:flex;"><span>clusterrole.rbac.authorization.k8s.io/system:metrics-server created
</span></span><span style="display:flex;"><span>rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
</span></span><span style="display:flex;"><span>clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
</span></span><span style="display:flex;"><span>clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
</span></span><span style="display:flex;"><span>service/metrics-server created
</span></span><span style="display:flex;"><span>deployment.apps/metrics-server created
</span></span><span style="display:flex;"><span>apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 查看运行状态</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 kubeadm-metrics-server<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl get po -A | grep metrics</span>
</span></span><span style="display:flex;"><span>kube-system   metrics-server-5cf8885b66-2nnb6            1/1     Running   <span style="color:#ae81ff">0</span>             68s
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 部署后便可以查看指标了</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 kubeadm-metrics-server<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl top node</span>
</span></span><span style="display:flex;"><span>NAME           CPU<span style="color:#f92672">(</span>cores<span style="color:#f92672">)</span>   CPU%   MEMORY<span style="color:#f92672">(</span>bytes<span style="color:#f92672">)</span>   MEMORY%   
</span></span><span style="display:flex;"><span>k8s-master01   177m         8%     1196Mi          64%       
</span></span><span style="display:flex;"><span>k8s-master02   153m         7%     1101Mi          58%       
</span></span><span style="display:flex;"><span>k8s-master03   163m         8%     1102Mi          58%       
</span></span><span style="display:flex;"><span>k8s-node01     88m          4%     848Mi           45%       
</span></span><span style="display:flex;"><span>k8s-node02     85m          4%     842Mi           45%       
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 kubeadm-metrics-server<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl top po</span>
</span></span><span style="display:flex;"><span>NAME                     CPU<span style="color:#f92672">(</span>cores<span style="color:#f92672">)</span>   MEMORY<span style="color:#f92672">(</span>bytes<span style="color:#f92672">)</span>   
</span></span><span style="display:flex;"><span>nginx-85b98978db-7mn6r   0m           3Mi
</span></span></code></pre></div><h2 id="部署dashboard">部署Dashboard<a hidden class="anchor" aria-hidden="true" href="#部署dashboard">#</a></h2>
<p>Dashboard是一个展示Kubernetes集群资源和Pod日志，甚至可以执行容器命令的web控制台。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 直接部署即可</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 kubeadm-metrics-server<span style="color:#f92672">]</span><span style="color:#75715e"># cd /root/k8s-ha-install/dashboard/</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 dashboard<span style="color:#f92672">]</span><span style="color:#75715e"># ls</span>
</span></span><span style="display:flex;"><span>dashboard-user.yaml  dashboard.yaml
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 dashboard<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl apply -f .</span>
</span></span><span style="display:flex;"><span>serviceaccount/admin-user created
</span></span><span style="display:flex;"><span>clusterrolebinding.rbac.authorization.k8s.io/admin-user created
</span></span><span style="display:flex;"><span>namespace/kubernetes-dashboard created
</span></span><span style="display:flex;"><span>serviceaccount/kubernetes-dashboard created
</span></span><span style="display:flex;"><span>service/kubernetes-dashboard created
</span></span><span style="display:flex;"><span>secret/kubernetes-dashboard-certs created
</span></span><span style="display:flex;"><span>secret/kubernetes-dashboard-csrf created
</span></span><span style="display:flex;"><span>secret/kubernetes-dashboard-key-holder created
</span></span><span style="display:flex;"><span>configmap/kubernetes-dashboard-settings created
</span></span><span style="display:flex;"><span>role.rbac.authorization.k8s.io/kubernetes-dashboard created
</span></span><span style="display:flex;"><span>clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
</span></span><span style="display:flex;"><span>rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
</span></span><span style="display:flex;"><span>clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
</span></span><span style="display:flex;"><span>deployment.apps/kubernetes-dashboard created
</span></span><span style="display:flex;"><span>service/dashboard-metrics-scraper created
</span></span><span style="display:flex;"><span>deployment.apps/dashboard-metrics-scraper created
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 查看dashboard端口，默认是NodePort模式，访问集群内任意节点的31073端口即可</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 dashboard<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl get svc -owide -A | grep dash</span>
</span></span><span style="display:flex;"><span>kubernetes-dashboard   dashboard-metrics-scraper   ClusterIP   10.105.172.8    &lt;none&gt;        8000/TCP                 19m    k8s-app<span style="color:#f92672">=</span>dashboard-metrics-scraper
</span></span><span style="display:flex;"><span>kubernetes-dashboard   kubernetes-dashboard        NodePort    10.99.148.159   &lt;none&gt;        443:31073/TCP            19m    k8s-app<span style="color:#f92672">=</span>kubernetes-dashboard
</span></span></code></pre></div><p>访问dashboard：<a href="https://%e9%9b%86%e7%be%a4%e5%86%85%e4%bb%bb%e6%84%8f%e8%8a%82%e7%82%b9IP:31073"  target="_blank" rel="noopener" style="color:#42b983" ;>https://集群内任意节点IP:31073</a></p>
<p>发现提示隐私设置错误的问题，如图：</p>
<p><img loading="lazy" src="https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213153948.png" alt="20211213153948"  />
</p>
<p>在Chrome浏览器启动参数加入<code>--test-type --ignore-certificate-errors</code>，然后再访问就没有这个安全提示了</p>
<p><img loading="lazy" src="https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213154024.png" alt="20211213154024"  />
</p>
<p><img loading="lazy" src="https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213154133.png" alt="20211213154133"  />
</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 获取登陆令牌（token）</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 dashboard<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#39;{print $1}&#39;)</span>
</span></span><span style="display:flex;"><span>Name:         admin-user-token-mwnfs
</span></span><span style="display:flex;"><span>Namespace:    kube-system
</span></span><span style="display:flex;"><span>Labels:       &lt;none&gt;
</span></span><span style="display:flex;"><span>Annotations:  kubernetes.io/service-account.name: admin-user
</span></span><span style="display:flex;"><span>              kubernetes.io/service-account.uid: 29584392-1cbd-4d5c-91af-9dd4703008aa
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Type:  kubernetes.io/service-account-token
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Data
</span></span><span style="display:flex;"><span><span style="color:#f92672">====</span>
</span></span><span style="display:flex;"><span>ca.crt:     <span style="color:#ae81ff">1099</span> bytes
</span></span><span style="display:flex;"><span>namespace:  <span style="color:#ae81ff">11</span> bytes
</span></span><span style="display:flex;"><span>token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IjRyZlh6Ukxta0FlajlHREF5ei1mdl8tZmR6ekwteV9fVEIwalQtejRwUk0ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLW13bmZzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIyOTU4NDM5Mi0xY2JkLTRkNWMtOTFhZi05ZGQ0NzAzMDA4YWEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06YWRtaW4tdXNlciJ9.pMBMkLAP2AoymIXJC7H47IPu3avdBWPYSZfvjRME7lEQAnbe-SM-yrTFGPzcsJQC3O9gPDvXgIZ1x1tQUtQhc_333GtDMj_VL9oEZxYiOdd578CnBiFmF0BWVX06pAzONgKbguamMD8XEPAvKt4mnlDUr7WCeQJZf_juXKdl7ZOBtrM5Zae0UQHFG6juKLmFP-XxIgoDVIPhcxeAH1ktOHM9Fk1M831hywL1SL2OLHiN52wGLT4WuYrP2iUbJkNpt2PYitSp3iNuh7rESL4Ur7lmFQkLZa9e5vNMCc1wTwOAWvaW4P5TbxtfI_ng4NK_avquiXJY-67D77G-8WKzWg
</span></span></code></pre></div><p><img loading="lazy" src="https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213154451.png" alt="20211213154451"  />
</p>
<h2 id="集群优化可选">集群优化(可选)<a hidden class="anchor" aria-hidden="true" href="#集群优化可选">#</a></h2>
<p>Docker可在<code>/etc/docker/daemon.json</code>自定义优化配置，所有配置可见：<a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file"  target="_blank" rel="noopener" style="color:#42b983" ;>官方docker configuration</a>，docker常用优化配置见下方注释说明。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 优化docker配置</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># /etc/docker/daemon.json文件，按需配置，不需要全部都照抄，使用时删除注释，因为JSON文件不支持注释</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;exec-opts&#34;</span>: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;native.cgroupdriver=systemd&#34;</span><span style="color:#f92672">]</span>, <span style="color:#75715e"># cgroups驱动</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;registry-mirrors&#34;</span>: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;https://ynirk4k5.mirror.aliyuncs.com&#34;</span><span style="color:#f92672">]</span>, <span style="color:#75715e"># 镜像加速器地址</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;allow-nondistributable-artifacts&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;api-cors-header&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;authorization-plugins&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;bip&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;bridge&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;cgroup-parent&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;cluster-advertise&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;cluster-store&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;cluster-store-opts&#34;</span>: <span style="color:#f92672">{}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;containerd&#34;</span>: <span style="color:#e6db74">&#34;/run/containerd/containerd.sock&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;containerd-namespace&#34;</span>: <span style="color:#e6db74">&#34;docker&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;data-root&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>, <span style="color:#75715e"># 数据根目录，大量docker镜像可能会占用较大存储，可以设置系统盘外的挂载盘</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;debug&#34;</span>: true,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-address-pools&#34;</span>: <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;base&#34;</span>: <span style="color:#e6db74">&#34;172.30.0.0/16&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;size&#34;</span>: <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;base&#34;</span>: <span style="color:#e6db74">&#34;172.31.0.0/16&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;size&#34;</span>: <span style="color:#ae81ff">24</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-cgroupns-mode&#34;</span>: <span style="color:#e6db74">&#34;private&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-gateway&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-gateway-v6&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-runtime&#34;</span>: <span style="color:#e6db74">&#34;runc&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-shm-size&#34;</span>: <span style="color:#e6db74">&#34;64M&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-ulimits&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;nofile&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Hard&#34;</span>: 64000,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Name&#34;</span>: <span style="color:#e6db74">&#34;nofile&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Soft&#34;</span>: <span style="color:#ae81ff">64000</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;dns&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;dns-opts&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;dns-search&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;exec-root&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;experimental&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;features&#34;</span>: <span style="color:#f92672">{}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;fixed-cidr&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;fixed-cidr-v6&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;group&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;hosts&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;icc&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;init&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;init-path&#34;</span>: <span style="color:#e6db74">&#34;/usr/libexec/docker-init&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;insecure-registries&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;ip&#34;</span>: <span style="color:#e6db74">&#34;0.0.0.0&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;ip-forward&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;ip-masq&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;iptables&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;ip6tables&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;ipv6&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;labels&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;live-restore&#34;</span>: true, <span style="color:#75715e"># docker进程宕机时容器依然保持存活</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;log-driver&#34;</span>: <span style="color:#e6db74">&#34;json-file&#34;</span>, <span style="color:#75715e"># 日志格式</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;log-level&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>, <span style="color:#75715e"># 日志级别</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;log-opts&#34;</span>: <span style="color:#f92672">{</span> <span style="color:#75715e"># 日志优化</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cache-disabled&#34;</span>: <span style="color:#e6db74">&#34;false&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cache-max-file&#34;</span>: <span style="color:#e6db74">&#34;5&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cache-max-size&#34;</span>: <span style="color:#e6db74">&#34;20m&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cache-compress&#34;</span>: <span style="color:#e6db74">&#34;true&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;env&#34;</span>: <span style="color:#e6db74">&#34;os,customer&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;labels&#34;</span>: <span style="color:#e6db74">&#34;somelabel&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;max-file&#34;</span>: <span style="color:#e6db74">&#34;5&#34;</span>, <span style="color:#75715e"># 最大日志数量</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;max-size&#34;</span>: <span style="color:#e6db74">&#34;10m&#34;</span> <span style="color:#75715e"># 保存的最大日志大小</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;max-concurrent-downloads&#34;</span>: 3, <span style="color:#75715e"># pull下载并发数</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;max-concurrent-uploads&#34;</span>: 5, <span style="color:#75715e"># push上传并发数</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;max-download-attempts&#34;</span>: 5,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;mtu&#34;</span>: 0,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;no-new-privileges&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;node-generic-resources&#34;</span>: <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;NVIDIA-GPU=UUID1&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;NVIDIA-GPU=UUID2&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;oom-score-adjust&#34;</span>: -500,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;pidfile&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;raw-logs&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;runtimes&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cc-runtime&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;path&#34;</span>: <span style="color:#e6db74">&#34;/usr/bin/cc-runtime&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;custom&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;path&#34;</span>: <span style="color:#e6db74">&#34;/usr/local/bin/my-runc-replacement&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;runtimeArgs&#34;</span>: <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;--debug&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;seccomp-profile&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;selinux-enabled&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;shutdown-timeout&#34;</span>: 15,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;storage-driver&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;storage-opts&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;swarm-default-advertise-addr&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;tls&#34;</span>: true,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;tlscacert&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;tlscert&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;tlskey&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;tlsverify&#34;</span>: true,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;userland-proxy&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;userland-proxy-path&#34;</span>: <span style="color:#e6db74">&#34;/usr/libexec/docker-proxy&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;userns-remap&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 无注释版</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;exec-opts&#34;</span>: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;native.cgroupdriver=systemd&#34;</span><span style="color:#f92672">]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;registry-mirrors&#34;</span>: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;https://ynirk4k5.mirror.aliyuncs.com&#34;</span><span style="color:#f92672">]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;containerd-namespace&#34;</span>: <span style="color:#e6db74">&#34;docker&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;data-root&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;debug&#34;</span>: true,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-cgroupns-mode&#34;</span>: <span style="color:#e6db74">&#34;private&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-gateway&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-gateway-v6&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-runtime&#34;</span>: <span style="color:#e6db74">&#34;runc&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-shm-size&#34;</span>: <span style="color:#e6db74">&#34;64M&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;default-ulimits&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;nofile&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Hard&#34;</span>: 64000,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Name&#34;</span>: <span style="color:#e6db74">&#34;nofile&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Soft&#34;</span>: <span style="color:#ae81ff">64000</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;init-path&#34;</span>: <span style="color:#e6db74">&#34;/usr/libexec/docker-init&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;live-restore&#34;</span>: true,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;log-driver&#34;</span>: <span style="color:#e6db74">&#34;json-file&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;log-level&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;log-opts&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cache-disabled&#34;</span>: <span style="color:#e6db74">&#34;false&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cache-max-file&#34;</span>: <span style="color:#e6db74">&#34;5&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cache-max-size&#34;</span>: <span style="color:#e6db74">&#34;20m&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cache-compress&#34;</span>: <span style="color:#e6db74">&#34;true&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;env&#34;</span>: <span style="color:#e6db74">&#34;os,customer&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;labels&#34;</span>: <span style="color:#e6db74">&#34;somelabel&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;max-file&#34;</span>: <span style="color:#e6db74">&#34;5&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;max-size&#34;</span>: <span style="color:#e6db74">&#34;10m&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;max-concurrent-downloads&#34;</span>: 3,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;max-concurrent-uploads&#34;</span>: 5,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;max-download-attempts&#34;</span>: 5,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;mtu&#34;</span>: 0,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;no-new-privileges&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;oom-score-adjust&#34;</span>: -500,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;pidfile&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;raw-logs&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;runtimes&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cc-runtime&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;path&#34;</span>: <span style="color:#e6db74">&#34;/usr/bin/cc-runtime&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;custom&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;path&#34;</span>: <span style="color:#e6db74">&#34;/usr/local/bin/my-runc-replacement&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;runtimeArgs&#34;</span>: <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;--debug&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;seccomp-profile&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;selinux-enabled&#34;</span>: false,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;shutdown-timeout&#34;</span>: 15,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;storage-driver&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;storage-opts&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;swarm-default-advertise-addr&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;userland-proxy-path&#34;</span>: <span style="color:#e6db74">&#34;/usr/libexec/docker-proxy&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;userns-remap&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 设置证书有效期</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 ~<span style="color:#f92672">]</span><span style="color:#75715e"># vim /usr/lib/systemd/system/kube-controller-manager.service</span>
</span></span><span style="display:flex;"><span>... <span style="color:#75715e"># 加入下面配置</span>
</span></span><span style="display:flex;"><span>--experimental-cluster-signing-duration<span style="color:#f92672">=</span>876000h0m0s
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 ~<span style="color:#f92672">]</span><span style="color:#75715e"># systemctl daemon-reload</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 ~<span style="color:#f92672">]</span><span style="color:#75715e"># systemctl restart kube-controller-manager</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># kubelet优化加密算法，默认的算法容易被漏洞扫描；增长镜像下载周期，避免有些大镜像未下载完成就被动死亡退出</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># --image-pull-progress-deadline=30m</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 ~<span style="color:#f92672">]</span><span style="color:#75715e"># vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf</span>
</span></span><span style="display:flex;"><span>... <span style="color:#75715e"># 下面这行中KUBELET_EXTRA_ARGS=后加入配置</span>
</span></span><span style="display:flex;"><span>Environment<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;KUBELET_EXTRA_ARGS=--tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 --image-pull-progress-deadline=30m&#34;</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 集群配置优化，详见https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 ~<span style="color:#f92672">]</span><span style="color:#75715e"># vim /etc/kubernetes/kubelet-conf.yml</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 文件中添加如下配置</span>
</span></span><span style="display:flex;"><span>rotateServerCertificates: true
</span></span><span style="display:flex;"><span>allowedUnsafeSysctls: <span style="color:#75715e"># 允许在修改内核参数，此操作按情况选择，用不到就不用设置</span>
</span></span><span style="display:flex;"><span> - <span style="color:#e6db74">&#34;net.core*&#34;</span>
</span></span><span style="display:flex;"><span> - <span style="color:#e6db74">&#34;net.ipv4.*&#34;</span>
</span></span><span style="display:flex;"><span>kubeReserved: <span style="color:#75715e"># 为Kubernetes集群守护进程组件预留资源，例如：kubelet、Runtime等</span>
</span></span><span style="display:flex;"><span>  cpu: <span style="color:#e6db74">&#34;100m&#34;</span>
</span></span><span style="display:flex;"><span>  memory: 100Mi
</span></span><span style="display:flex;"><span>  ephemeral-storage: 1Gi
</span></span><span style="display:flex;"><span>systemReserved: <span style="color:#75715e"># 为系统守护进程预留资源，例如：sshd、cron等</span>
</span></span><span style="display:flex;"><span>  cpu: <span style="color:#e6db74">&#34;100m&#34;</span>
</span></span><span style="display:flex;"><span>  memory: 100Mi
</span></span><span style="display:flex;"><span>  ephemeral-storage: 1Gi
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 更改kube-proxy模式为ipvs</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 dashboard<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl edit cm kube-proxy -n kube-system</span>
</span></span><span style="display:flex;"><span>mode: <span style="color:#e6db74">&#34;ipvs&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 更新kube-proxy的pod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 dashboard<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl patch daemonset kube-proxy -p &#34;{\&#34;spec\&#34;:{\&#34;template\&#34;:{\&#34;metadata\&#34;:{\&#34;annotations\&#34;:{\&#34;date\&#34;:\&#34;`date +&#39;%s&#39;`\&#34;}}}}}&#34; -n kube-system</span>
</span></span><span style="display:flex;"><span>daemonset.apps/kube-proxy patched
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 验证</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 dashboard<span style="color:#f92672">]</span><span style="color:#75715e"># curl 127.0.0.1:10249/proxyMode</span>
</span></span><span style="display:flex;"><span>ipvs
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 为集群节点打标签，删除标签把 = 换成 - 即可</span>
</span></span><span style="display:flex;"><span>kubectl label nodes k8s-node01 node-role.kubernetes.io/node<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>kubectl label nodes k8s-node02 node-role.kubernetes.io/node<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>kubectl label nodes k8s-master01 node-role.kubernetes.io/master<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>kubectl label nodes k8s-master02 node-role.kubernetes.io/master<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>kubectl label nodes k8s-master03 node-role.kubernetes.io/master<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 添加标签后查看集群状态</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 ~<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl get node</span>
</span></span><span style="display:flex;"><span>NAME           STATUS   ROLES    AGE    VERSION
</span></span><span style="display:flex;"><span>k8s-master01   Ready    master   100m   v1.23.0
</span></span><span style="display:flex;"><span>k8s-master02   Ready    master   100m   v1.23.0
</span></span><span style="display:flex;"><span>k8s-master03   Ready    master   100m   v1.23.0
</span></span><span style="display:flex;"><span>k8s-node01     Ready    node     100m   v1.23.0
</span></span><span style="display:flex;"><span>k8s-node02     Ready    node     100m   v1.23.0
</span></span></code></pre></div><p>生产环境建议ETCD集群和Kubernetes集群分离，而且使用高性能数据盘存储数据，根据情况决定是否将Master节点也作为Pod调度节点。</p>
<h2 id="测试集群">测试集群<a hidden class="anchor" aria-hidden="true" href="#测试集群">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 测试namespace</span>
</span></span><span style="display:flex;"><span>kubectl get namespace
</span></span><span style="display:flex;"><span>kubectl create namespace test
</span></span><span style="display:flex;"><span>kubectl get namespace
</span></span><span style="display:flex;"><span>kubectl delete namespace test
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 创建nginx实例并开放端口</span>
</span></span><span style="display:flex;"><span>kubectl create deployment nginx --image<span style="color:#f92672">=</span>nginx
</span></span><span style="display:flex;"><span>kubectl expose deployment nginx --port<span style="color:#f92672">=</span><span style="color:#ae81ff">80</span> --type<span style="color:#f92672">=</span>NodePort
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 查看调度状态和端口号</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>root@k8s-master01 calico<span style="color:#f92672">]</span><span style="color:#75715e"># kubectl get pod,svc -owide</span>
</span></span><span style="display:flex;"><span>NAME                         READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES
</span></span><span style="display:flex;"><span>pod/nginx-85b98978db-7mn6r   1/1     Running   <span style="color:#ae81ff">0</span>          2m16s   172.27.14.193   k8s-master02   &lt;none&gt;           &lt;none&gt;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>        AGE    SELECTOR
</span></span><span style="display:flex;"><span>service/kubernetes   ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP        59m    &lt;none&gt;
</span></span><span style="display:flex;"><span>service/nginx        NodePort    10.104.33.99   &lt;none&gt;        80:31720/TCP   2m6s   app<span style="color:#f92672">=</span>nginx
</span></span></code></pre></div><p>可见调度到了k8s-master02（IP地址是192.168.43.184）上，对应的NodePort为31720</p>
<p>在浏览器输入<a href="http://192.168.43.184:31720/"  target="_blank" rel="noopener" style="color:#42b983" ;>http://192.168.43.184:31720/</a> 访问nginx，访问结果如图</p>
<p><img loading="lazy" src="https://deemoprobe.oss-cn-shanghai.aliyuncs.com/images/20211213143124.png" alt="20211213143124"  />
</p>
<p>至此，基于kubeadm的Kubernetes高可用集群部署并验证成功。</p>


        </div>

        <footer class="post-footer">
            
<nav class="paginav">
  <a class="prev" href="https://deemoprobe.github.io/posts/tech/kubernetes/kubernetesbinaryinstallation-ha/">
    <span class="title">« 上一页</span>
    <br>
    <span>KubernetesBinaryInstallation HA</span>
  </a>
  <a class="next" href="https://deemoprobe.github.io/posts/tech/kubernetes/kubernetesarchitecture-ha/">
    <span class="title">下一页 »</span>
    <br>
    <span>KubernetesArchitecture HA</span>
  </a>
</nav>

        </footer>
    </div>
</article>
</main>

<footer class="footer">
    
        <span id="runtime_span"></span>
        <script
            type="text/javascript">function show_runtime() { window.setTimeout("show_runtime()", 1000); X = new Date("1/1/2023 1:00:00"); Y = new Date(); T = (Y.getTime() - X.getTime()); M = 24 * 60 * 60 * 1000; a = T / M; A = Math.floor(a); b = (a - A) * 24; B = Math.floor(b); c = (b - B) * 60; C = Math.floor((b - B) * 60); D = Math.floor((c - C) * 60); runtime_span.innerHTML = "网站已运行" + A + "天" + B + "小时" + C + "分" + D + "秒" } show_runtime();</script>
    
    
    <br>
    <span>
        Copyright
        &copy;
        2022-2023
        <a href="https://deemoprobe.github.io/" style="color:#939393;">William&#39;s Blog</a>
        All Rights Reserved
    </span>
    
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"William's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"William's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = '📄复制';

        function copyingDone() {
            copybutton.innerText = '👌🏻已复制!';
            setTimeout(() => {
                copybutton.innerText = '📄复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\n————————————————\r\n' +
                    '版权声明：本文为「'+"William's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        }
    });
</script>

<script>
    $("code[class^=language] ").on("mouseover", function () {
        if (this.clientWidth < this.scrollWidth) {
            $(this).css("width", "135%")
            $(this).css("border-top-right-radius", "var(--radius)")
        }
    }).on("mouseout", function () {
        $(this).css("width", "100%")
        $(this).css("border-top-right-radius", "unset")
    })
</script>
</body>

</html>
